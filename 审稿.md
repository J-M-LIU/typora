

# A Novel High Compression-Rate Image Compression Framework Based on Optimal Transport Mapping



## Abstract

In this paper, we introduce a novel high compression-rate image compression approach that utilizes optimal transport (OT) mapping to achieve a high compression rate while preserving fine image details.  We first utilize an automatic encoder to embed the low dimensional image manifold into the latent space and map the data distribution to the latent code distribution.  The decoder then reconstructs the latent code back to the data manifold.  Subsequently, we calculate the OT map from the noise distribution to the latent code distribution.  Finally, our GAN model is trained to generate images based on the latent distribution induced by the OT map.  Experimental results demonstrate that our method outperforms other GAN-based techniques under objective criteria, particularly at high compression rates.  Our method solves mode collapse/mode mixture issues during GAN image generation.  The precise description capabilities of the OT map facilitate appropriate reconstruction of compressed images.

本文提出一种新的高压缩率图像压缩方法，利用最优传输(OT)映射实现高压缩率的同时保留图像细节。首先利用自动编码器将低维图像流形嵌入到隐空间，并将数据分布映射到隐代码分布;然后解码器将潜在代码重构回数据流形。然后，计算从噪声分布到潜在代码分布的OT分布图。最后，基于OT映射诱导的潜在分布训练GAN模型生成图像。实验结果表明，该方法在客观标准下优于其他基于gan的技术，**特别是在高压缩率下**。该方法解决了GAN图像生成过程中的模式坍缩/模式混合问题。OT映射精确的描述能力便于对压缩图像进行适当的重建。

 ## Introduction

In recent years, image compression has become a crucial aspect of multimedia data storage and transmission due to the growing demand for efficient data handling and resource optimization. Traditional image compression techniques, such as JPEG (Wallace 1992) and PNG (Surhone et al. 2016), have long been utilized, but they often struggle to strike a balance between achieving high compression rates and preserving fine image details. This limitation becomes particularly pronounced when dealing with high compression rates, leading to a loss of critical visual information and reduced image quality.

近年来，由于人们对高效数据处理和资源优化的需求日益增长，图像压缩已成为多媒体数据存储和传输的一个重要方面。传统的图像压缩技术，如JPEG (Wallace 1992)和PNG (Surhone et al. 2016)，已经被使用了很长时间，但它们往往难以在实现高压缩率和保留图像细节之间取得平衡。**当处理高压缩率时，这种限制尤其明显，这会导致关键视觉信息的丢失和图像质量的下降。**

To overcome these challenges, there is a need for innovative image compression methods that can achieve high compression rates while retaining essential visual features. In response to this demand, we propose a new approach that leverages OT for image compression. The concept of OT, with its ability to accurately measure the distance between two probability measures, presents a promising avenue for achieving better compression and reconstruction performance, even under stringent compression constraints.

为了克服这些挑战，需要创新的图像压缩方法，**在保持基本视觉特征的同时实现高压缩率**。为响应这一需求，本文提出一种利用OT进行图像压缩的新方法。OT的概念能够精确测量两个概率度量之间的距离，为实现更好的压缩和重构性能提供了一条有希望的途径，即使在严格的压缩约束下。

Image compression poses several challenges that need to be addressed to improve overall performance. First and foremost, striking a balance between achieving high compression rates and maintaining image fidelity is a delicate task. Conventional compression methods often sacrifice fine details in pursuit of higher compression rates, resulting in a loss of image quality and visual appeal.

图像压缩带来了几个需要解决的挑战，以提高整体性能。首先，在实现高压缩率和保持图像保真度之间取得平衡是一项微妙的任务。传统的压缩方法往往牺牲细节来追求更高的压缩率，导致图像质量和视觉吸引力的损失。

Another challenge arises from the use of generative adversarial networks (GANs) for image generation, which can suffer from mode collapse or mode mixture. Mode collapse occurs when the GAN generates limited variations of images, leading to repetitive and unrealistic outputs. Mode mixture, on the other hand, refers to the blending of different modes in the generated images, resulting in blurred or distorted representations.

另一个挑战来自于使用生成对抗网络(GANs)进行图像生成，这可能会受到模式崩溃或模式混合的影响。当GAN生成有限的图像变化时，就会发生模式崩溃，导致重复和不现实的输出。另一方面，模式混合是指将生成的图像中的不同模式进行混合，从而导致图像的表示模糊或扭曲。

The primary objective of this paper is to propose a new high compression-rate image compression method that overcomes the challenges posed by traditional techniques and GAN-based image generation. By incorporating OT, our approach aims to achieve high compression rates while effectively preserving the crucial visual details in the compressed images.

本文的主要目标是提出一种新的高压缩率图像压缩方法，克服传统技术和基于gan的图像生成带来的挑战。通过结合OT，该方法旨在实现高压缩率，同时有效保留压缩图像中的关键视觉细节。

Specifically, our contributions are as follows:

1. Introducing an innovative image compression method based on OT map, which accurately measures the distance between probability measures, thereby improving image reconstruction quality. 
2. Addressing mode collapse and mode mixture issues in GAN-generated images by utilizing an automatic encoder and an extended OT map, ensuring the generation of diverse and realistic images. 
3. Conducting comprehensive experimental evaluations to demonstrate the effectiveness of our proposed method in comparison to existing GAN-based image compression techniques, showcasing its superior performance under various compression rates. 

1. **引入一种基于OT映射的图像压缩方法**，准确度量概率测度之间的距离，从而提高图像重构质量。

2. 通过利用自动编码器和扩展OT映射**解决gan生成图像中的模式崩溃和模式混合问题**，确保生成多样化和真实的图像。

3. 进行了全面的实验评估，与现有的基于gan的图像压缩技术相比，所提方法的有效性，展示了其**在各种压缩率下的优越性能**。

The rest of the paper is organized as follows: In Section 2, we provide a comprehensive review of related works in image compression techniques and GAN-based image generation. Section 3 presents the details of our proposed high compression-rate image compression method using the OT map. We outline the framework, discuss the utilization of the automatic encoder, and elaborate on the computation of the OT map. Section 4, details the experimental setup, including the dataset used, evaluation metrics, and baseline methods for comparison. Section 5, presents the results and analysis of our approach, comparing its performance against existing GAN-based techniques under different compression rates. Finally, in Section 6, we conclude our work by summarizing the contributions of the proposed approach, discussing potential applications, and providing concluding remarks on its effectiveness in high compression-rate image compression.

本文的其余部分组织如下:在第2节中，全面回顾了图像压缩技术和基于gan的图像生成的相关工作。第3节介绍了我们提出的使用OT映射的高压缩率图像压缩方法的细节。我们概述了框架，讨论了自动编码器的应用，并详细阐述了OT映射的计算。第4节详细介绍了实验设置，包括使用的数据集、评估指标和用于比较的基线方法。第5节给出了该方法的结果和分析，在不同的压缩率下将其与现有的基于gan的技术进行了性能比较。最后，在第6节中，总结了所提出方法的贡献，讨论了潜在的应用，并对其在高压缩率图像压缩中的有效性进行了总结。

## Related Work

Image compression technologies have been extensively explored to reduce the data size of images while retaining their visual quality. Traditional methods, such as JPEG (Wallace 1992) and PNG (Surhone et al. 2016), have been widely used, but they often struggle to preserve fine details under high compression rates. Recent advancements have shown that neural compression systems, including those based on autoencoders and variational autoencoders, can achieve better compression performance while maintaining satisfactory image quality (Theis et al. 2017). Additionally, adversarial loss has been incorporated into neural compression systems to improve visual quality and enhance compression efficiency (Toderici et al. 2015, 2017). However, there is still a need for further research to overcome the limitations of traditional compression techniques and improve the performance of neural compression methods.

GANs have demonstrated remarkable progress in generating high-resolution and photorealistic images (Brock, Donahue, and Simonyan 2018; Karras, Laine, and Aila 2019; Park et al. 2019). This progress has been attributed to factors such as increased training data, larger model scales, and innovative network architectures (Brock, Donahue, and Simonyan 2018; Karras, Laine, and Aila 2019). Additionally, stable training techniques and antagonistic loss have played vital roles in improving the visual quality of GAN-generated images (Miyato et al. 2018). GANs have been applied to image compression, where GAN discriminators have been used as decoders in compression systems (Santurkar, Budden, and Shavit 2018). Researchers have also explored incorporating GAN loss into the rate-distortion trade-off in image compression pipelines (Blau and Michaeli 2019). Moreover, GAN-based compression systems have shown promising results in saving bit rates at high compression rates compared to traditional compression algorithms (Agustsson et al. 2019).

OT has found successful applications in various fields, such as economics, optics, and machine learning (Solomon 2018). OT provides an accurate measure of distance between probability measures, making it well-suited for image compression tasks. The connection between OT’s Brenier theory and convex geometry’s Alexandroff theory has been established and applied to deep learning (Gu et al. 2013). However, when dealing with non-convex data distribution support, the transport map may encounter discontinuities (Chen and Figalli 2017; Figalli 2010). Recent research has explored the challenges of mode collapse and mode mixture in GANs (Nagarajan and Kolter 2017). Several approaches, including gradient-based regularization and the use of multiple GANs, have been proposed to mitigate mode collapse (Khayatkhoei, Elgammal, and Singh 2018; Liu et al. 2019).

Despite these efforts, effectively addressing mode mixture in GAN-based applications remains an open challenge.

In light of the aforementioned advancements and limitations in image compression and GAN-based approaches, this paper proposes a new high compression-rate image compression method that utilizes an OT map to preserve fine image details while achieving high compression rates. By combining the strengths of OT and GANs, our approach aims to overcome the mode collapse and mode mixture challenges typically encountered in GAN-based image generation and compression systems. The subsequent sections of this paper present a detailed description of our proposed method and comprehensive experimental evaluations to showcase its superior performance under various compression scenarios.

图像压缩技术被广泛用于减小图像的数据量，同时保持图像的视觉质量。传统的方法，如JPEG (Wallace 1992)和PNG (Surhone et al. 2016)，已经被广泛使用，但它们往往很难在高压缩率下保持细节。最近的进展表明，神经压缩系统，包括基于自编码器和变分自编码器的神经压缩系统，可以实现更好的压缩性能，同时保持令人满意的图像质量(Theis et al. 2017)。此外，对抗性损失已被纳入神经压缩系统，以改善视觉质量并提高压缩效率(Toderici et al. 2015, 2017)。然而，克服传统压缩技术的局限性，提高神经压缩方法的性能仍然需要进一步的研究。

GANs在生成高分辨率和逼真图像方面取得了显著进展(Brock、Donahue和Simonyan 2018;Karras, Laine和Aila 2019;Park et al. 2019)。这一进展归因于训练数据增加、模型规模更大和创新的网络架构等因素(Brock, Donahue和Simonyan 2018;Karras, Laine和Aila 2019)。此外，稳定的训练技术和拮抗损失在提高gan生成图像的视觉质量方面发挥了至关重要的作用(Miyato et al. 2018)。GANs已应用于图像压缩，其中GAN鉴别器已被用作压缩系统中的解码器(Santurkar、Budden和Shavit 2018)。研究人员还探索了将GAN损失纳入图像压缩管道中的率失真权衡(Blau和Michaeli 2019)。此外，与传统压缩算法相比，基于gan的压缩系统在高压缩率下节省比特率方面表现出了有希望的结果(Agustsson等人2019)。

OT在各个领域都有成功的应用，例如经济学、光学和机器学习(Solomon 2018)。OT提供了概率度量之间距离的精确度量，非常适合图像压缩任务。OT的Brenier理论和凸几何的Alexandroff理论之间的联系已经建立并应用于深度学习(Gu et al. 2013)。然而，在处理非凸数据分布支持时，运输图可能会遇到不连续(Chen and Figalli 2017;Figalli 2010)。最近的研究探索了GANs中模式崩溃和模式混合的挑战(Nagarajan和Kolter 2017)。已经提出了几种方法来缓解模式崩溃，包括基于梯度的正则化和使用多个GANs (Khayatkhoei, Elgammal, and Singh 2018;Liu et al. 2019)。

尽管有这些努力，在基于gan的应用中有效解决模式混合仍然是一个开放的挑战。

鉴于上述图像压缩和基于gan的方法的优势和局限性，本文提出了一种新的高压缩率图像压缩方法，利用OT映射在实现高压缩率的同时保留图像细节。通过结合OT和gan的优势，该方法旨在克服基于gan的图像生成和压缩系统中通常遇到的模式崩溃和模式混合挑战。本文的后续部分详细描述了所提出的方法，并进行了全面的实验评估，以展示其**在各种压缩场景下的优越性能**。

## Architecture

### Overview of Proposed Method

The architecture of our image compression method comprises four essential stages, illustrated in 

1. Embedding Image Data into a Low-dimensional Latent Space: In this phase, the original image data X undergoes dimensionality reduction through an automatic encoder fθ . The encoder function fθ learns to map X to a lower-dimensional latent space Z, i.e., Z = fθ (X), while minimizing the reconstruction loss to retain vital image features. 
1. Generating a Uniform Distribution in the Latent Space: A uniform distribution µ spanning the latent space Z is generated by sampling latent codes from a standard normal distribution and applying a non-linear transformation ˜T. 
1. Compute the OT Map: Leveraging the semi-discrete OT map, this stage generates latent codes that align with the target distribution. The semi-discrete OT map capitalizes on the unique properties of OT to accurately preserve pixel relationships, mitigating mode collapse and mixture challenges. 
1. Training the GAN Model: A GAN model is trained to generate high-quality images using the latent codes produced by the semi-discrete OT map. The GAN’s generator and discriminator collaboratively enhance image generation quality.


1. 将图像数据嵌入到低维隐空间:在此阶段，原始图像数据X通过自动编码器fθ进行降维。编码器函数fθ学习将X映射到低维隐空间Z，即Z = fθ (X)，同时最小化重建损失以保留重要的图像特征。

2. 在潜空间中生成均匀分布:横跨潜空间Z的均匀分布μ是通过从标准正态分布中采样潜代码并应用非线性变换~ T而生成的。

3. 计算OT映射:利用半离散OT映射，此阶段生成与目标分布一致的潜代码。半离散OT映射利用OT的独特特性来准确地保持像素关系，减轻模式崩溃和混合挑战。

4. 训练GAN模型:使用半离散OT映射产生的潜代码训练GAN模型生成高质量的图像。GAN的生成器和鉴别器协同提高了图像生成质量。

These components synergistically contribute to our image compression approach. The embedding and OT phases handle dimensionality reduction and pixel relationship preservation, effectively addressing mode collapse and mixture issues. Subsequent GAN training further refines image quality by aligning the image generation process with the latent distribution induced by the semi-discrete OT map.

这些组件协同地促进了图像压缩方法。嵌入和OT阶段处理了降维和像素关系保持，有效地解决了模式崩溃和混合问题。随后的GAN训练通过将图像生成过程与半离散OT映射诱导的潜分布对齐来进一步细化图像质量。

## Experiment Setup

### Dataset

To rigorously evaluate the performance and generalizability of our proposed models, we conducted a series of experiments using the PyTorch framework (Paszke 2019).Our training dataset comprises an extensive collection of high-resolution images, sourced from various online repositories and supplemented with selected images from the IMDBWIKI dataset (Rothe, Timofte, and Gool 2018). To demonstrate the robustness of our method beyond the training data, we extensively evaluate our models on three additional independent datasets, namely, the widely used Kodak dataset (24 images) (Franzen 1997), the CLIC2021 dataset (428 images) (CLIC 2021), the RAISE1k dataset (Dang-Nguyen et al. 2015), and the DIV2K dataset (100 images). The inclusion of these diverse datasets, which feature a wide range of image characteristics, allows us to ascertain the generalization capabilities of our approach across different image types and qualities. 

When working with the CLIC dataset, we handle all images in the RGB color space, disregarding specific color profiles to ensure consistency in our evaluations. The RAISE1k and DIV2K datasets are particularly relevant for assessing the performance of our method on high-resolution images, as they predominantly comprise images with dimensions exceeding 1600×1600 pixels.

为了严格评估所提出模型的性能和泛化能力，我们使用PyTorch框架(Paszke 2019)进行了一系列实验。我们的训练数据集包括一个广泛的高分辨率图像集合，来自各种在线存储库，并辅以来自IMDBWIKI数据集的选定图像(Rothe, Timofte和Gool 2018)。为了证明所提方法在训练数据之外的鲁棒性，在三个额外的独立数据集上广泛评估了所提模型，即广泛使用的Kodak数据集(24张图片)(Franzen 1997)、CLIC2021数据集(428张图片)(CLIC 2021)、RAISE1k数据集(Dang-Nguyen等人2015)和DIV2K数据集(100张图片)。这些具有广泛图像特征的不同数据集的包含，使我们能够确定所提出方法对不同图像类型和质量的泛化能力。

在处理CLIC数据集时，我们在RGB颜色空间中处理所有图像，忽略特定的颜色配置文件，以确保评估的一致性。RAISE1k和DIV2K数据集与评估所提出方法在高分辨率图像上的性能特别相关，因为它们主要由尺寸超过1600×1600像素的图像组成。

### Evaluation Metrics

To quantitatively measure and compare the performance of our proposed models against baseline methods, we adopt a comprehensive set of evaluation metrics widely used in image compression and generation tasks.  These evaluation metrics encompass the following: PSNR (Peak Signal-to-Noise Ratio) (Sheikh, Sabir, and Bovik 2006): 

PSNR is a well-established index for assessing the quality of compressed images.  It quantifies the ratio of the maximum pixel intensity to the noise level, thereby providing a measure of pixel similarity between the compressed image and the original image.  Higher PSNR values indicate better reconstruction quality. 

MS-SSIM (Multi-Scale Structural Similarity) (Wang, Simoncelli, and Bovik 2003): MS-SSIM is a perceptual metric that evaluates neural compression systems based on structural similarity.  Unlike PSNR, MS-SSIM considers human perception, capturing the image’s structural information across multiple scales. 

LPIPS (Learned Perceptual Image Patch Similarity) (Zhang et al. 2018b): LPIPS measures the distance between image patches in the feature space of a deep neural network.  Originally designed for image classification, LPIPS has proven effective in predicting the similarity of distorted image patches, demonstrating strong correlation with human perceptual scores. 

FID (Frechet Inception Distance) (Heusel et al. 2017): Widely used for evaluating GAN performance in image generation tasks, FID measures the distance between the distributions of generated and real images.  Lower FID values indicate better diversity and quality of generated samples.

为了定量衡量和比较所提出模型与基线方法的性能，采用了一套广泛用于图像压缩和生成任务的全面评估指标。这些评价指标包括以下内容:PSNR(峰值信噪比)(Sheikh、Sabir和Bovik, 2006年):

峰值信噪比(PSNR)是评价压缩图像质量的一个行之有效的指标。它量化了最大像素强度与噪声水平的比率，从而提供了压缩图像和原始图像之间像素相似性的度量。PSNR值越高，重建质量越好。

MS-SSIM (Multi-Scale Structural Similarity，多尺度结构相似性)(Wang、Simoncelli和Bovik, 2003): MS-SSIM是一种基于结构相似性评估神经压缩系统的感知度量方法。与PSNR不同，MS-SSIM考虑了人类的感知，捕捉了图像的多尺度结构信息。

LPIPS(学习感知图像块相似性)(Zhang et al. 2018b): LPIPS在深度神经网络的特征空间中测量图像块之间的距离。LPIPS最初是为图像分类而设计的，已被证明在预测失真图像块的相似性方面是有效的，与人类感知分数具有很强的相关性。

FID (Frechet Inception Distance) (Heusel et al. 2017): FID广泛用于评估GAN在图像生成任务中的性能，衡量生成图像的分布与真实图像之间的距离。FID值越低，生成样本的多样性和质量越好。



### Baseline Methods

To ensure comprehensive comparison, we benchmark the performance of our proposed models against several established baseline methods, which include state-of-the-art image compression techniques and widely used GAN-based approaches for image generation.  By evaluating our method against these benchmarks, we aim to demonstrate its superiority in terms of compression efficiency and image reconstruction quality.

为确保全面的比较，将所提出模型的性能与几个已建立的基线方法进行了基准测试，其中包括最先进的图像压缩技术和广泛使用的基于gan的图像生成方法。通过将所提出方法与这些基准进行评估，旨在证明其在压缩效率和图像重建质量方面的优越性。

### Implementation Details

During the training phase, we adopt a patch-based approach by randomly cropping image patches of size 256×256 from the training images. The chosen batch size for training is set to 8, optimizing computational efficiency while maintaining training stability.

To facilitate efficient training, we employ the Adam optimizer with parameters β 1 = 0.9 and β 2 = 0.999.  The initial learning rate is set to 1e −4 , and we incorporate a learning rate scheduler, halving the learning rate at the 100,000th and 300,000th iterations to facilitate convergence.

To validate the robustness of our framework against mode collapse, we conduct additional training using face data.  This supplementary training dataset includes 200,000 face images sourced from the CelebA dataset (Liu et al. 2015) and 13,000 face images from the MTFL dataset (Zhang et al. 2014).  Subsequently, we leverage this retrained model to compress face images and assess its performance.

By meticulously designing our experimental setup and employing an array of diverse evaluation metrics, we aim to comprehensively validate the effectiveness and adaptability of our proposed high compression-rate image compression method.  Through these evaluations, we seek to highlight its advantages over existing techniques and establish its potential for real-world applications.

在训练阶段，我们采用一种基于块的方法，从训练图像中随机裁剪大小为256×256的图像块。选择用于训练的批大小设置为8，在保持训练稳定性的同时优化计算效率。

为了促进有效的训练，我们采用了Adam优化器，参数β 1 = 0.9和β 2 = 0.999。初始学习率设置为1e−4，并加入了一个学习率调度器，在第10万次和第30万次迭代时将学习率减半，以促进收敛。

为了验证该框架对模式崩溃的鲁棒性，我们使用人脸数据进行了额外的训练。这个补充训练数据集包括来自CelebA数据集的20万张人脸图像(Liu et al. 2015)和来自MTFL数据集的1.3万张人脸图像(Zhang et al. 2014)。利用这个重新训练的模型来压缩人脸图像，并评估其性能。

通过精心设计实验装置并采用一系列不同的评价指标，旨在全面验证所提出的高压缩率图像压缩方法的有效性和适应性。通过这些评估，试图强调其相对于现有技术的优势，并建立其在现实世界应用的潜力。

## Results

### Objective Evaluation

Performance under High Compression Rates: To showcase the advantages of our method under high compression rates, we set BPP of the image to 0.03 and compared our results with GAN-based high compression rate algorithms (Agustsson et al. 2019) and traditional algorithms (Bellard 2017). We evaluated PSNR and MS-SSIM on the Kodak (Franzen 1997), RAISE1K (Dang-Nguyen et al. 2015), and CLIC2021 datasets (CLIC 2021).

Fig. 2 reveals that our method significantly outperforms other GAN algorithms and traditional methods when BPP is around 0.03.  This enhancement can be attributed to the use of OT, which effectively filters out modes in the singular set of the latent space distribution, leading to improved preservation of essential mode information when generating the compressed image. 

高压缩率下的性能:为了展示该方法在高压缩率下的优势，将图像的BPP设置为0.03，并将结果与基于gan的高压缩率算法(Agustsson et al. 2019)和传统算法(Bellard 2017)进行比较。我们在Kodak (Franzen 1997)、RAISE1K (Dang-Nguyen等人2015)和CLIC2021数据集(CLIC 2021)上评估了PSNR和MS-SSIM。

从图2可以看出，当BPP在0.03左右时，我们的方法明显优于其他GAN算法和传统方法。这种增强可以归功于OT的使用，它有效地过滤了潜空间分布的奇异集中的模式，从而提高了在生成压缩图像时对本质模式信息的保留。

**Comparison with Baseline Methods**: To evaluate the performance of our proposed models objectively, we conducted rate-distortion and rate-perception curve analyses using four widely-used metrics, namely PSNR, MS-SSIM, LPIPS, and FID.  Figures 3 and 4 display the rate-distortion and rate-perception curves, respectively, based on evaluations performed on the publicly available CLIC2021 dataset.  We compare our method against several baseline methods, including HiFiC (Mentzer et al. 2020), GMM (Gaussian mixture model) (Cheng et al. 2020), AEDC (auto encoderbased deep compression) (Agustsson et al. 2019), and BPG (better portable graphics) (Bellard 2017).  Similar results were obtained on the Kodak dataset. 

Our method demonstrates favorable performance in terms of PSNR and MS-SSIM, as compared to HiFiC, a state-of-the-art learning-based image compression method with advanced visual quality.  When considering other metrics like LPIPS, our model exhibits higher PSNR and MS-SSIM scores but slightly lower LPIPS scores.  Notably, PSNR and MS-SSIM are indicators more inclined towards the objective quality of images.  Therefore, our model’s superior performance in these two metrics indicates its ability to maintain high image quality during compression.  We observed that by adjusting the proportion of the perception index in the loss function, we can achieve a balance between PSNR and MS-SSIM measures, aligning with the distortion-perception trade-off principle.

为了客观评价所提模型的性能，采用PSNR、MS-SSIM、LPIPS和FID这4个被广泛使用的指标进行了率失真和率感知曲线分析。图3和图4分别显示了基于在公开可用的CLIC2021数据集上进行的评估的率失真曲线和率感知曲线。将该方法与几种基线方法进行了比较，包括HiFiC (Mentzer等人2020)、GMM(高斯混合模型)(Cheng等人2020)、AEDC(基于自动编码器的深度压缩)(Agustsson等人2019)和BPG(更好的便携式图形)(Bellard 2017)。在Kodak数据集上也得到了类似的结果。

与目前最先进的基于学习的图像压缩方法HiFiC相比，该方法在PSNR和MS-SSIM指标上均表现出良好的性能。当考虑LPIPS等其他指标时，所提出模型表现出更高的PSNR和MS-SSIM分数，但LPIPS分数略低。值得注意的是，PSNR和MS-SSIM是更倾向于图像客观质量的指标。因此，所提出模型在这两个指标上的优越性能表明其在压缩期间保持高图像质量的能力。我们观察到，通过调整感知指数在损失函数中的比例，可以在PSNR和MS-SSIM度量之间实现平衡，符合失真-感知权衡原则。

**Ablation studies**: The ablation experiments conducted across different BPPs underscore the consistent advantages of the OT+GAN approach over standalone GAN and OT methods.In Table. 1, Table. 2 and Table. 3, the results, measured in terms of PSNR, MS-SSIM, and LPIPS with different BPP, reveal a clear pattern of superior performance exhibited by the OT+GAN hybrid approach. At every BPP level, the OT+GAN consistently outperforms GAN and OT counterparts, achieving higher PSNR, MS-SSIM, and perceptual quality scores. This consistency emphasizes the effectiveness of integrating OT with generative adversarial networks in achieving enhanced image compression results across a spectrum of compression rates.

在不同BPPs上进行的消融实验强调了OT+GAN方法相对于单独的GAN和OT方法的一致优势。在表1、表2和表3中，以不同BPP的PSNR、MS-SSIM和LPIPS衡量的结果显示，OT+GAN混合方法表现出了明显的优越性能。在每个BPP水平上，OT+GAN始终优于GAN和OT，实现了更高的PSNR、MS-SSIM和感知质量分数。这种一致性强调了将OT与生成式对抗网络相结合在实现跨频谱压缩率的图像压缩结果方面的有效性。

### Subjective Evaluation

**Fine Details Preservation:**

Fig. 5 displays a comparison between our proposed method and other GAN algorithms (Agustsson et al. 2019) and BPG (Bellard 2017) on the Kodak and RAISE1K datasets under very high compression rates. Despite the rapid increase in distortion under very high compression rates, our method effectively retains the basic structure of the image, keeping it clear and preserving essential features, such as the stamen part in the lower half of the image. Figs. 6 and 7 provide two additional examples, both demonstrating our method’s superior performance at high compression rates. Notably, our method benefits from the property of OT, as it does not cause mode mixture or mode collapse underhigh compression rates, mitigating issues typically associated with GAN algorithms.

Through these objective and subjective evaluations, our proposed high compression-rate image compression method proves its superiority over existing techniques, particularly under high compression rates. The use of OT enhances compression accuracy by avoiding mode collapse, ultimately leading to better preservation of fine image details and improved visual quality.

图5显示了我们提出的方法与其他GAN算法(Agustsson et al. 2019)和BPG (Bellard 2017)在Kodak和RAISE1K数据集上在非常高的压缩率下的比较。尽管在很高的压缩率下，失真度会迅速增加，但该方法有效地保留了图像的基本结构，保持了图像的清晰，并保留了图像的基本特征，如图像的下半部分的雄蕊部分。图6和图7提供了两个额外的例子，都证明了所提出方法在高压缩率下的优越性能。值得注意的是，所提出方法受益于OT的特性，因为它在高压缩率下不会导致模式混合或模式崩溃，减轻了通常与GAN算法相关的问题。

通过客观和主观评价，我们提出的高压缩率图像压缩方法证明了其优越性，特别是在高压缩率下。OT的使用通过避免模式崩溃提高了压缩精度，最终导致更好地保留图像细节和改善视觉质量。

**Mode collapse**

Fig. 8 exemplifies the successful avoidance of mode collapse under high compression rates. The GAN-based method struggles to retain the character’s teeth and eyes’ intricate details, leading to noticeable artifacts. In contrast, the OT-based method excels in precisely calculating the distribution mapping, ensuring the preservation of image details even when subjected to high compression rates. This example underscores the effectiveness of the OT approach in maintaining image quality and overcoming challenges associated with mode collapse. On the facial dataset, this mode collapse is most evident, which is related to the manifold distribution of the dataset.

图8展示了在高压缩率下成功避免模式崩溃的例子。基于gan的方法很难保留角色的牙齿和眼睛的复杂细节，导致明显的伪影。相比之下，基于ot的方法在精确计算分布映射方面表现突出，即使在受到高压缩率的情况下也能保证图像细节的保留。这个例子强调了OT方法在保持图像质量和克服与模式崩溃相关的挑战方面的有效性。在面部数据集上，这种模式崩溃最明显，这与数据集的流形分布有关。

## Discussion and Conclusions

Our proposed GAN-based learned compression method outperforms prior works, achieving high-quality compression while preserving fine details. By leveraging the OT map, we overcome mode collapse and achieve superior performance under high compression rates. The integration of GANs and OT provides an efficient and robust solution applicable to various data distributions. Although the perceptual quality is not as good as other GAN-based methods at low compression rates, we will still make improvements and optimize the new model in terms of perceptual quality. Extensive experiments validate our method’s effectiveness and promise for practical applications in image compression technologies.

所提出的基于gan的学习压缩方法优于之前的工作，在保留细节的同时实现了高质量的压缩。通过利用OT map，克服了模式崩溃，并在高压缩率下取得了优越的性能。gan与OT的结合提供了一种适用于各种数据分布的高效鲁棒的解决方案。虽然在低压缩率下的感知质量不如其他基于gan的方法，但我们仍然会在感知质量方面进行改进和优化。大量实验验证了该方法的有效性和在图像压缩技术中的实际应用前景。



**Summary Of The Paper:**

Preserving fine image details while achieving high compression rates has been a challenge for traditional image compression techniques. This limitation becomes more evident when dealing with high compression rates, resulting in a loss of critical visual information and reduced image quality. To address this limitation, this paper introduces an image compression approach that leverages optimal transport mapping. By utilizing this technique, the proposed approach achieves a high compression rate while preserving fine image details. Additionally, this approach effectively solves mode collapse and mode mixture issues during GAN image generation.

**Main Review**:

**Strengths**：

1. 本文提出一种基于semi-discrete optimal transport的生成式图像压缩方法，验证了本方法在高压缩率下对于保留图像关键视觉细节的有效性，并与之前的基于GAN模型的方法进行对比，验证了OT map对于解决模式崩溃和模式混合问题的有效性。



**Concerns：**

1. <u>没有必要将[2]《AE-OT A NEW GENERATIVE MODEL BASED ON EXTENDED SEMI-DISCRETE OPTIMAL TRANSPORT》中关于OT map的算法原理大篇幅写入本文中，因为相对于该文章，OT map上并没有做修改和创新，也没有其他实验的分析。</u>

2. <u>论文整体的构思感觉像直接参考论文[2]中的GAN结构，然后简单应用于image compression.</u>

3. 尽管由Figure 8可以观察出，OT map 在保持图像质量和克服与模式崩溃相关的挑战方面的有效性，尤其是在面部数据集上，但我不认同作者所说的“Addressing mode collapse and mode mixture issues in GAN-generated images by utilizing an automatic encoder and an extended OT map”是一个贡献：semi-discrete optimal transport在[2]中被首次提出，并证明了其对于解决模式崩溃和模式混合的问题的有效性。Could the authors please clarify if my understanding is correct?  In case it is, the claim should be changed to better reflect the contribution of the paper.

4. <u>Rate-distortion performance is rarely shown outside the 0.4 bpp range. Since the losses appear to be more evident at higher bitrate, it would be instructive to know if GAN+OT is as successful outside of the low to medium quality range. 贡献3中提到展示各种压缩率下的性能，但实际限制</u>

5. <u>在Introduction中，以GAN作为图像压缩的基本框架的背景和动机不足。文章中应首先介绍和强调使用GAN进行图像压缩的适用场景，one typical use case for GC are bandwidth constrained scenarios, where one wants to preserve the full image as well as possible, while falling back to synthesized content instead of blocky/blurry blobs for regions for which not sufﬁcient bits are available to store the original pixels.  特别是作者多次强调在高压缩率下的图像关键视觉细节的保留，但文章中，生成式压缩对于图像细节的重构和保留的重要性介绍并未提及，并且缺少相关的文献介绍。本文没有充分介绍以GAN作为图像压缩的基本框架的背景和动机</u>

   

6. <u>对于OT map的引入，没有做充分的动机介绍，没有从实际的详细实验中分析为什么参考OT map，导致文章中的关键创新方法，也就是OT map的引入显得动机不足，有些突兀。</u>

**Summary Of The Review:**

**Technical Novelty And Significance**：贡献不显著，在我看来是完全参考[2]中的OT map方法，再结合现有的基于GAN模型的图像压缩框架。

