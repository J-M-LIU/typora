**低延迟场景下的端到端编码**

## 研究内容



### 基于学习的视频编码轻量化：量化、混合精度、ROI、知识蒸馏





### 基于视觉感知的语义编码模型：

语义mask、显著对象检测、人脸ROI区域、其他ROI区域、



### 端到端的码率控制和可变码率



以往的视频压缩的大多数方法旨在改进重建视频质量，而非特别保留AI任务所需的语义信息，这会降低下游AI任务的完成效果。此外，任务无关的网络将编码系统与下游任务解耦，并且对于数据稀缺情况友好，但鲜有编码方法是任务无关的。本文试图建立一套方法满足上述两个要求。为解决压缩期间丢失的语义信息，本文提出了语义挖掘并补偿（SMC）框架作为基线方法，以提高当前普通视频编解码器的语义编码能力。至于框架的自监督优化，本文以MAE作为基本方法，并引入NSS进一步抑制非语义信息。本文提出的方法在广泛的任务范围内表现出色，且无需利用任何数据标签。



下游任务包括：语义分割、目标检测、视频感知等等，







图像压缩是图像处理和计算机视觉中最基本的问题之一。一些基于VAE的图像压缩方法需要训练多个固定码率的模型来实现可变码率，每个模型用于一个码率点。因此，训练成本和内存需求随着所需速率范围的增长和细化而急剧增加。其他一些方法不使用多个模型，而是使用一个单一的模型实现可变码率。例如，基于RNN的方法采用渐进式编码的方式，这种方法的RD性能较差。条件自编码器的方法将全连接层与卷积层相结合来实现离散的可变码率，但这种方法明显增加了模型的复杂度和内存需求。混合量化仓大小的方法虽然可以将码率从有限的离散点扩展到可变范围，但该方法会导致RD性能的下降。bottleneck缩放方法忽略了自编码器和缩放参数之间的兼容性，在低比特率范围内性能较差。尽管在单一模型中提供了可行的可变码率解决方案，但上述方法有各种实际问题，如性能下降、计算复杂性增加和内存增加。





智能任务飞速发展，分类、检测、分割等任务深入生活的方方面面。与此同时，语义压缩这一需求日渐显著，即，在保持信号源原有的语义信息的同时，尽可能减少压缩所需的带宽。然而，直接将语义度量集成到传统编解码器中是不切实际的，因为它们不能以端到端方式进行优化。为了解决这个问题，一些开创性的工作已经应用强化学习来实现与图像相关的语义信息的压缩优化。然而，由于视频压缩过程中复杂的参考架构和压缩方式，视频语义压缩一直没有得到深入的研究。基于此，本文提出了基于分层强化学习的任务驱动视频语义编码方法(HRLVSC)。具体而言，为了简化视频编码过程中复杂的模式决策，我们将决策空间划分为帧级和编码树单元(CTU)级，然后在帧级和CTU级强化学习智能体的协同下逐步探索它们的最佳模式选择。此外，鉴于视频编码的可选模式会随着一组图片(GOP)的帧数呈指数增长，我们仔细研究了不同模式选择对视频语义编码的影响，并设计了一种简单而有效的模式简化策略。



**显著性**

事实上，图片的显著性检测与人眼视觉系统是相契合的。由于人眼存在视觉聚焦机制，在观看一张图片时，主要的观察对象也是图片中的显著性部分。因此可以在视频编码中利用显著性检测，进一步针对人眼视觉的冗余信息进行消除。

利用人眼的视觉聚焦机制，可以通过**降低视频中的非显著性区域的分辨率**，保留显著性区域的分辨率不变，来尽可能的减小视觉质量的损失和降低码率大小。在显著性区域的划分上，可以使用现有的成熟的显著性检测模型来实现不同区域的定义。并且，在编码过程中，也可以**利用显著性检测的相关信息来辅助编码的过程**。

视觉感知提取人眼更为感兴趣的区域：ROI

ROI形式：
屏幕中心区域：

人脸





综上所述，这项研究的总体目标是将深度学习的先进技术应用于视频编码领域，以提高视频编码的效率、灵活性和智能度。通过这些研究，我们期望为处理不断增长的视频数据提供更有效的技术解决方案，为未来的视频传输和存储技术的发展奠定基础。
