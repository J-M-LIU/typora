# UNI-AIMS

## Intro

显微图像（如SEM、TEM等）在材料科学和生命科学中至关重要，但分析过程面临以下挑战：

- **传统方法局限性**：人工分析效率低、主观性强，难以应对持续增长的海量数据 。
- **场景复杂性**：图像中常包含数以千计、相互堆叠且大小不一的密集目标，且背景复杂、边界模糊 。
- **数据匮乏**：高质量、带标注的材料科学显微图像数据集非常稀缺，标注工作需要极高的专业知识 。
- **缺乏通用性**：现有模型通常仅针对特定设备或特定样本，难以跨领域应用 。

Uni-AIMS 的目标是建立一个覆盖从数据获取、自动标注到深度模型训练及多任务应用的统一平台，并且支持不同密度（稀疏、密集）实例分割。

## Related Work

**目标检测/分割方法**：

- **基于锚点 (Anchor-based)**：如 Mask R-CNN，在处理超密集或严重重叠的目标时性能下降明显 。
- **一阶段方法**：如 YOLACT，虽然速度快，但牺牲了掩码质量 。
- **中心/形状驱动方法**：如 CenterMask 或 StarDist，处理规则凸起物体效果好，但对不规则形状表现不佳 。

**现有自动化工具**：如 ImageDataExtractor，通常仅支持特定厂家或固定样式的标尺识别，缺乏通用性。



## 数据引擎与生成

现有标注工具：LabelMe、Label Studio在单张图片超过4000个分割实例情况下性能不稳定。

### 开发在线数据引擎

人机协同标注：采用两阶段迭代。第一阶段由专家标注少量标准数据训练初始模型；第二阶段利用模型生成伪标签，由志愿者在平台上进行修正，最后由材料专家审核 。

### 数据生成

阶段1：视觉概念与掩码的学习与生成（在极少样本下利用LoRA学习视觉特征）

- **Image-LoRA**：专门用于拟合特定材料的视觉概念（如颜色、明暗、背景纹理等）。
- **Mask-LoRA**：用于拟合不同材料实例的几何掩码（Mask）特征 。
- **批量掩码生成**：结合 Mask-LoRA 和启发式 Python 脚本，系统可以大批量地随机生成各种形状和分布的实例分割掩码。

阶段2：图像-掩码配对数据合成，生成大量带标注的配对数据

- **引入 ControlNet**：将渲染好的实例分割掩码作为**条件输入**。
- **协同生成**：在 Image-LoRA 的增强下，扩散模型（如 SDXL）以生成的掩码为蓝图，填充对应的视觉纹理，从而产生高度逼真的合成图像。

### 通用数据集 UniEM-3M

构建通用数据集 UniEM-3M，包含5091张电子显微镜图像和300万个标注实例：

- 图像模态：SEM、TEM、STEM、OM、FIB 等多种显微镜图像，包含 BSE、SE、EBSD 等成像方式；
- 典型结构种类：颗粒、纳米线、薄膜、孔洞、截面、团簇、纤维等；
- 样品类型：生物细胞、金属合金、陶瓷、复合材料、纳米颗粒、半导体器件、电池材料、磁性材料等。



## 系统架构与技术实现

### Flow-based Segmentation

模型学习从几何边界指向中心的定向流场（Directional Fields），通过模拟像素动力学（Pixel Dynamics）将像素导向各自的收敛中心，从而有效分离密集排列的目标。在处理形状复杂且排列紧密的显微对象（如细胞、颗粒）时具有显著优势 。

典型Flow-Based分割方案：HoverNet，Cellpose，CellViT，在密集实例分割场景中表现较好。

### 网络结构

- **编码器（Encoder）**：模型具有灵活性，可根据计算资源切换主干网络，包括 U-Net、ResNet、ResNeXt 以及高性能的 Vision Transformer (**ViT**) 或 Swin Transformer 。
- **多头解码器（Multi-head Decoder）**：解码器会生成多种几何信息，包括概率图（Probability）、流场（Flow Field）和地形图（Topography） 。
- **GPU 加速后处理**：针对 8K 超高分辨率图像，使用 **CUDA** 加速后处理过程，单张 8K 图像的推断时间缩短至约 80 秒 。

### 标尺识别架构 (Scale Bar Recognition)

标尺识别是显微图像定量分析中的关键技术，其核心作用是将图像中的**像素尺寸**转换为**真实的物理尺寸**（如微米 μm 或纳米 nm）。没有标尺识别，显微镜观察到的物体就只能以像素衡量，无法进行颗粒直径、孔隙密度或缺陷长度等具有科学意义的定量测量。

为什么需要自动标尺识别？传统的标尺处理方法存在显著局限性：

- 人工测量：耗时且具有主观性，难以处理大规模数据集。
- 固定阈值/模板匹配：显微镜品牌众多，标尺样式、字体、背景各异，传统算法在复杂背景下容易失效。

流程：

1. 检测定位：YOLOv8m模型同时检测图像中的标尺区域和文字区域
2. 文字识别：使用**PaddleOCR** 引擎识别标尺旁边的文字内容（例如 "10 μm"）



## 与其他Flow-Based方法的优化？

### 数据集

引入**SDXL + LoRA + ControlNet** 的合成数据引擎。通过极少量样本学习特定材料的视觉概念，并批量生成带有精确掩码的合成图像，用于大规模预训练。采用扩散模型生成大量图像-掩码配对标注数据，而非固定的公开数据集（在材料科学领域，高质量标注数据极端匮乏且存在严重的“长尾分布”问题，即稀疏或罕见场景的数据不足）

### 强调系统性解决方案

标注-数据生成-训练-识别-标尺识别的系统流程解决方案，并且集成了高精度的**标尺识别模块 Scale Bar Recognition**，能够自动识别各种厂家风格的标尺并提取物理尺寸。这是实现显微图像定量分析（如计算真实的颗粒直径分布）的前提，而 Cellpose 等算法通常需要用户手动设置像素转换比例。

### 架构灵活性

根据计算资源切换backbone，对于计算资源有限场景/数据不充足情况可使用轻量级 **U-Net**，对于高精度科研任务/数据充足使用 **Swin Transformer** 或大型 **ViT** 主干网络。

