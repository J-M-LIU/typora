[TOC]

ps查看进程状态，可以使用grep筛选进程

ps -T -p <pid> # 查看进程pid下的所有线程

如何使用Linux命令查看jvm线程？

ps -ef | grep java # 查看java线程ID

jsatck <pid> # 查看java线程情况

jinfo -flags <pid> # 查看java线程的JVM参数

jstat -gc <pid> # 查看Java线程的gc情况

jstat -gcutil <pid> # 查看java线程的堆内存情况

jstat -class <pid> # 查看java线程的类加载情况







## Java

### 基础



#### 基本数据类型

1. **整型**:
   - `byte`：占用 1 个字节，表示 -128 到 127 的整数。
   - `short`：占用 2 个字节，表示 -32,768 到 32,767 的整数。
   - `int`：占用 4 个字节，表示 -2^31 到 2^31-1 的整数。
   - `long`：占用 8 个字节，表示 -2^63 到 2^63-1 的整数。
2. **浮点型**:
   - `float`：占用 4 个字节，用来表示单精度（32位）浮点数。
   - `double`：占用 8 个字节，用来表示双精度（64位）浮点数。
3. **字符型**:
   - `char`：占用 2 个字节，用来表示单一的 16 位 Unicode 字符。
4. **布尔型**:
   - `boolean`：虽然具体实现依赖于 JVM，但通常用 1 位来表示，实际存储时常常使用 1 个字节。

对于 `char` 类型，它占用 2 个字节，主要是因为 Java 使用 Unicode 字符集，每个字符按照 UTF-16 编码标准存储，因此每个字符需要 2 个字节来存储。



#### 对面向对象的三大特性的理解

**封装**

封装是面向对象编程中用来将数据（属性）和代码（方法）绑定在一起的一种机制。它隐藏了类的内部细节和实现，只暴露出必要的接口给外部使用。这样做的主要目的是减少各个部分之间的依赖性，提高模块的独立性和可重用性。

- **如何实现**：在Java中，可以通过访问修饰符（如private, protected, public）来控制类成员的可见性，从而实现封装。
- **好处**：封装增加了代码的安全性，避免了外部对内部数据的直接访问。同时，它也提高了代码的可维护性，因为内部实现的改变不会影响到使用该类的代码。

**继承**

继承是一种可以让一个类继承另一个类的属性和方法的机制。这使得我们可以创建一个通用的类，然后建立更具体的子类来扩展或修改这些行为。

- **好处**：继承支持代码的重用，可以使得子类重用父类的方法和属性，不需要从零开始编写。同时，它也支持多态性。

**多态**

多态是指允许不同类的对象对同一消息作出响应的能力，即同一个接口可以被不同的对象以不同的方式实现。

- **静态多态**：通过方法重载（方法名相同，参数不同）实现。
- **动态多态**：通过方法重写（子类重写继承自父类的方法）和接口实现。在Java中，可以使用`override`关键字标示重写的方法。

- **好处**：多态性使得程序可以使用接口的通用形式编程，而由具体实现类决定执行哪个版本的方法，增加了程序的灵活性和可扩展性。



#### 泛型

**如何理解泛型**

Java泛型是一种在编程时提供类型安全的特性，允许你在类、接口和方法中使用类型参数。使用泛型可以让代码在处理不同数据类型时更加灵活且易于维护。

项目中哪里用到了泛型？

- 自定义接口通用返回结果 `CommonResult<T>` 通过参数 `T` 可根据具体的返回类型动态指定结果的数据类型
- 定义 `Excel` 处理类 `ExcelUtil<T>` 用于动态指定 `Excel` 导出的数据类型
- 构建集合工具类（参考 `Collections` 中的 `sort`, `binarySearch` 方法）。



#### String为什么是不可变的，有什么好处

在Java中，`String` 被设计为不可变的，这意味着一旦一个 `String` 对象被创建，其内容就不能被修改。这种设计有几个原因，并带来了一系列好处：

1. 安全性

由于 `String` 常常用来保存敏感数据，如网络连接的用户名和密码，不可变性可以保证这些信息在传递过程中不会被修改。如果 `String` 可变，那么数据就可能在未经授权的情况下被更改，从而引入安全漏洞。

2. 线程安全

多线程中，可变对象的值很可能被其他线程改变，造成不可预期的结果。而不可变的 String 可以自由在多个线程之间共享，不需要同步处理。

3. 字符串常量池（Interning）

字符串常量池（String pool）是 Java 堆内存中一个特殊的存储区域，当创建一个 String 对象时，假如此字符串已经存在于常量池中，则不会创建新的对象，而是直接引用已经存在的对象。这样做能够减少 JVM 的内存开销，提高效率。

4. 可靠性和哈希编码

`String` 被广泛用作 `HashMap`、`HashTable`、`HashSet` 等集合的键。不可变性保证了 `String` 的哈希码是不变的，这是散列表需要的一个重要特性。如果字符串是可变的，那么修改字符串的内容会改变其哈希码，这将破坏散列表的内部结构，导致数据存取错误。

5. 缓存哈希码

因为字符串不可变，所以在它创建的时候 hashcode 就被缓存了，不需要重新计算。这就使得字符串很适合作为 HashMap 中的 key，效率大大提高。



#### 序列化

序列化是指将对象转换为字节序列的过程，以便可以在网络上传输或者将对象保存到文件中。序列化的主要目的是将对象的状态转换为可以存储或传输的形式，以便在需要时可以重新创建相同的对象。

Java中有几种序列化的方法，其中最常用的是Java自带的序列化机制，即使用java.io.Serializable接口。除了Java原生的序列化方式外，还有一些其他的序列化方法，如JSON序列化、XML序列化等。

**Java原生的序列化方式：**

**Java序列化（java.io.Serializable）：**
Java提供了java.io.Serializable接口，让类可以实现序列化。当一个类实现了Serializable接口时，它的对象可以通过**ObjectOutputStream**写入到输出流中，并且可以通过**ObjectInputStream**从输入流中读取出来。

**其他序列化方法：**

1. JSON序列化：

   使用JSON（JavaScript Object Notation）将对象序列化为字符串或字节流的一种方式。Java中有许多JSON库（如Jackson、Gson等）可以用来序列化和反序列化Java对象。
   XML序列化：

2. **使用XML**（eXtensible Markup Language）将对象序列化为XML格式的字符串或字节流的一种方式。Java中可以使用DOM、SAX、JAXB等技术来实现XML序列化和反序列化。
   Protocol Buffers序列化：

3. Protocol Buffers是Google开发的一种高效的序列化方法，它使用二进制格式将结构化数据序列化为字节流。Java中可以使用Google的Protocol Buffers库来实现序列化和反序列化。
   Avro序列化：

4. Avro是一种高性能的数据序列化格式，它使用二进制编码，支持动态生成的数据模式。Java中可以使用Apache Avro库来实现序列化和反序列化。

JDK 自带的序列化方式一般不会用 ，因为序列化效率低并且存在安全问题。比较常用的序列化协议有 Hessian、Kryo、Protobuf、ProtoStuff，这些都是基于二进制的序列化协议。

**为什么不推荐使用 JDK 自带的序列化？**

我们很少或者说几乎不会直接使用 JDK 自带的序列化方式，主要原因有下面这些原因：

1. 不支持跨语言调用 : 如果调用的是其他语言开发的服务的时候就不支持了。
2. 性能差：相比于其他序列化框架性能更低，主要原因是序列化之后的字节数组体积较大，导致传输成本加大。
3. 存在安全问题：序列化和反序列化本身并不存在问题。但当输入的反序列化的数据可被用户控制，那么攻击者即可通过构造恶意输入，让反序列化产生非预期的对象，在此过程中执行构造的任意代码



#### 深拷贝 浅拷贝

**浅拷贝**：浅拷贝会在堆上创建一个新的对象（区别于引用拷贝的一点），不过，如果原对象内部的属性是引用类型的话，浅拷贝会直接复制内部对象的引用地址，也就是说拷贝对象和原对象共用同一个内部对象。

**深拷贝**：深拷贝会完全复制整个对象，包括这个对象所包含的内部对象。

**引用拷贝：** 简单来说，引用拷贝就是两个不同的引用指向同一个对象。

<img src="https://oss.javaguide.cn/github/javaguide/java/basis/shallow&deep-copy.png" style="zoom: 67%;" />





### 集合



![](https://oss.javaguide.cn/github/javaguide/java/collection/java-collection-hierarchy.png)



#### 线程安全问题

1. **第一代线程安全集合类**
   Vector、Hashtable
   是怎么保证线程安排的：使用**synchronized**修饰方法
   缺点：效率低下
2. **第二代线程非安全集合类**
   ArrayList、HashMap
   线程不安全，但是性能好，用来替代Vector、Hashtable
   使用ArrayList、HashMap,需要线程安全怎么办呢？
   **Collections.synchronizedList(list);Collections.synchronizedMap(m);**
   底层使用synchronized代码块锁虽然也是锁住了所有的代码，但是锁在方法里边，并所在方法外边性能可以理解
   为稍有提高吧。毕竟进方法本身就要分配资源的
3. **第三代线程安全集合类**
   在大量并发情况下如何提高集合的效率和安全呢？
   java.util.concurrent.*
   **ConcurrentHashMap**:
   **CopyOnWriteArrayList** 是一个线程安全的可变数组实现，适用于读多写少的场景。它提供了与ArrayList类似的API，并通过使用写时复制（Copy-On-Write）策略来实现高效的并发访问。
   **CopyOnWriteArraySet**:注意不是CopyOnWriteHashSet*
   底层大都采用Lock锁(1.8的ConcurrentHashMap不使用Lock锁)，保证安全的同时，性能也很高。



#### 红黑树数据结构，Java里哪里用到了

红黑树是一种自平衡的二叉查找树，它在Java中被广泛应用于各种数据结构和算法中。在Java中，红黑树通常被用于实现以下几种数据结构和算法：

1. **TreeMap**： TreeMap是Java中的一个基于红黑树实现的有序映射（SortedMap）。它使用红黑树来存储键值对，并且保持键的有序性。TreeMap提供了一系列方法来对键值对进行操作，如插入、删除、查找等。
2. **TreeSet**： TreeSet是Java中的一个基于红黑树实现的有序集合（SortedSet）。它使用红黑树来存储元素，并且保持元素的有序性。TreeSet提供了一系列方法来对元素进行操作，如插入、删除、查找等。
3. **NavigableMap和NavigableSet**： NavigableMap和NavigableSet是Java中的接口，它们扩展了SortedMap和SortedSet接口，提供了额外的导航方法。TreeMap和TreeSet实现了这两个接口，并使用红黑树来支持导航操作。
4. **ConcurrentSkipListMap和ConcurrentSkipListSet**： ConcurrentSkipListMap和ConcurrentSkipListSet是Java中的基于跳表（Skip List）实现的并发有序映射和集合。它们使用红黑树来辅助实现并发访问的功能。
5. **ConcurrentHashMap**： 在Java 8之前的版本中，ConcurrentHashMap的实现中使用了分段锁和链表来处理哈希冲突。但在Java 8及以后的版本中，它的实现采用了红黑树来替代链表，以提高并发性能。当链表长度超过一定阈值时，ConcurrentHashMap会将链表转换为红黑树，从而加速查找操作。

总之，红黑树在Java中被广泛用于实现有序映射、有序集合以及并发数据结构，它提供了高效的查找、插入和删除操作，并且能够保持元素的有序性和平衡性。



#### HaspMap和Treemap区别

`HashMap`和`TreeMap`都是Java集合框架中的重要组成部分，它们实现了`Map`接口，但内部结构和功能特性有明显的差异。这些差异导致它们在不同情况下的使用具有不同的性能表现和适用场景。

**HashMap**

1. **内部结构**：
   - `HashMap`基于哈希表实现。它使用键的哈希码来决定键值对的存储位置。如果两个或更多的键具有相同的哈希码，`HashMap`会使用链表或红黑树来解决冲突（JDK 1.8+在链表长度超过一定阈值时将链表转换为红黑树）。
2. **顺序**：
   - `HashMap`不保证任何顺序，即它不保证随着时间的推移Map中的数据顺序是恒定的。因此，迭代`HashMap`的结果是不可预测的。
3. **性能**：
   - `HashMap`提供常数时间的性能（O(1)）用于`get`和`put`方法，假设哈希函数将元素正确地分散在桶中。
4. **使用场景**：
   - 当应用需要快速查找且元素顺序不重要时，使用`HashMap`是一个好选择。

**TreeMap**

1. **内部结构**：
   - `TreeMap`基于红黑树实现。这种结构支持有序集合的操作，能够保证元素按照键的自然顺序或构造`TreeMap`时提供的`Comparator`进行排序。
2. **顺序**：
   - `TreeMap`保证了一个一致的排序顺序，这使得它在需要一个按排序顺序来遍历键的场景下非常有用。
3. **性能**：
   - `TreeMap`提供对数时间的性能（O(log n)）用于`get`、`put`和`remove`操作，这是因为它基于树结构。
4. **使用场景**：
   - 当需要一个总是有序的映射，或者需要按自然顺序或自定义顺序频繁地进行遍历时，`TreeMap`是更好的选择。

**主要区别**

- **性能**：`HashMap`通常比`TreeMap`快，特别是在键的分布均匀时。
- **排序**：`TreeMap`保证了顺序，而`HashMap`则不保证。
- **内存**：由于`TreeMap`使用红黑树，通常比`HashMap`使用更多的内存。
- **API**：`TreeMap`提供了一些特有的方法，如`firstKey`、`lastKey`、`higherKey`、`lowerKey`等，用于处理有序集合。



#### Collections工具类

java集合包 (HashSet, TreeSet, ArrayList, LinkedList, HashMap, TreeMap) 大多是“非线程安全的”，虽然可以通过Collections工具类中的方法获取java集合包对应的同步类，但是这些同步类的并发效率并不是很高。为了更好的支持高并发任务，并发大师Doug Lea在JUC(java.util.concurrent)包中添加了java集合包中单线程类的对应的支持高并发的类。

**Collections** 中的方法效率非常低

```java
synchronizedCollection(Collection<T>  c) //返回指定 collection 支持的同步（线程安全的）collection。
synchronizedList(List<T> list)//返回指定列表支持的同步（线程安全的）List。
synchronizedMap(Map<K,V> m) //返回由指定映射支持的同步（线程安全的）Map。
synchronizedSet(Set<T> s) //返回指定 set 支持的同步（线程安全的）set。
```



#### HashMap底层实现

1. **哈希表**：
   - `HashMap` 内部采用哈希表实现，通过哈希函数将键映射到哈希表的槽位（桶）上。
   - 哈希表的槽位是一个数组，每个槽位上可以存储一个**链表**（JDK8之前）或者一个红黑树（JDK8及之后），用于解决哈希冲突。
2. **哈希冲突解决**：
   - 当发生哈希冲突时，采用**拉链法/链地址法**（Separate Chaining）解决冲突，将冲突的键值对存储在对应槽位的链表或红黑树中。
   - JDK1.8 之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。
3. **动态扩容**：
   - `HashMap` 采用动态扩容机制，当哈希表的负载因子（元素数量与桶的数量之比）超过阈值（默认为 0.75）时，进行扩容。
   - 扩容操作会重新计算哈希值，并重新分配每个键值对到新的桶上，以保证哈希表的均匀性。
4. **扩容和重新哈希**：
   - 扩容操作会创建一个新的更大的哈希表，并将原来哈希表中的键值对重新哈希到新表中。
   - 重新哈希是一个耗时的操作，但由于哈希表的槽位数量翻倍，平均每个桶上的元素数量会减少一半，提高了查询效率。
5. **线程安全性**：
   - `HashMap` 是非线程安全的，不支持多线程并发访问。在多线程环境下，需要通过加锁或者使用 `ConcurrentHashMap` 来保证线程安全性。
6. **迭代顺序**：
   - `HashMap` 的迭代顺序不是严格按照键值对的插入顺序，而是根据哈希值和链表（或红黑树）的顺序确定的。
   - JDK8 中，由于链表转换为红黑树可能会改变键值对的相对顺序，因此迭代顺序可能不稳定。
7. **空间复杂度**：
   - `HashMap` 的空间复杂度是 O(n)，其中 n 表示存储的键值对数量。
   - 当元素数量增加时，哈希表需要动态扩容，因此空间复杂度与元素数量相关。

### 并发

#### 线程池工作过程

1. **创建线程池**：通过`ThreadPoolExecutor`创建线程池。
2. **提交任务**：将任务（实现了`Runnable`接口或`Callable`接口的对象）提交给线程池。
3. **任务排队**：如果线程池中的线程数小于核心线程数，任务会被立即分配给空闲的核心线程执行。如果核心线程都在执行任务，任务将被放入任务队列中等待执行。
4. **任务执行**：线程池中的线程执行任务。如果核心线程都在忙碌，但任务队列未满，线程池会创建新的非核心线程来处理任务。如果任务队列已满，且非核心线程数未达到最大线程数，线程池会根据策略创建新的非核心线程来执行任务。
5. **任务完成**：任务执行完成后，线程将返回线程池并准备接受新的任务。

#### 线程回收机制

线程池的线程回收机制主要是通过以下几种方式来实现：

1. **空闲线程回收**：当线程池中的线程空闲一定时间后（由`keepAliveTime`参数决定），会被回收并从线程池中移除，以节省资源。
2. **线程池大小调整**：一些线程池实现（如`ThreadPoolExecutor`）支持动态调整线程池的大小，根据任务量的变化动态增加或减少线程数，以适应系统负载的变化。
3. **非核心线程回收**：如果线程池中的线程数超过核心线程数，并且空闲一定时间后仍未接收到新任务，非核心线程将被回收。

#### 标记核心线程和非核心线程的原因

将线程分为核心线程和非核心线程的目的是为了优化线程池的性能和资源利用率：

1. **核心线程**：核心线程通常是在系统启动时就创建好的，它们可以一直存在于线程池中，即使没有任务执行也不会被回收，以保证线程池的响应速度。核心线程的存在可以减少线程的创建和销毁开销，提高线程的重复利用率。
2. **非核心线程**：非核心线程是在任务量增加时动态创建的，它们可以根据任务的数量来灵活调整线程池的大小，以应对不同的工作负载。非核心线程在空闲一定时间后会被回收，以释放资源，避免资源浪费。



#### 死锁

##### 死锁产生的必要条件

1. 互斥条件
   进程对所分配到的资源进行排它性使用，即在一段时间内，某资源只能被一个进程所占用。如果此时还有其他进程请求该资源，则请求进程只能等待，直至占有该资源的进程用完并释放资源。
2. 请求和保持条件
    进程已经保持了至少一个资源，但又提出新的资源请求，而该进程已经被其他进程占有，此时进行请求的进程将被阻塞，进入阻塞队列，但是对自己已经获得的资源保持不放。

3. 不可抢占条件
    进程已获得的资源在未使用之前不能被抢占，只能在进程使用完时由自己释放。

4. 循环等待条件
    在发生死锁时，必然存在一个进程–资源的循环链，即进程集合{P0，P1，…，Pn}中的P0正在等待一个P1占用的资源，P1正在等待P2占用的资源，…，Pn正在等待已被P0占用的资源。



在资源的动态分配过程中，用某种方法去防止系统进入不安全状态，从而避免发生死锁。 一般来说互斥条件是无法破坏的，所以在预防死锁时主要从其他三个方面入手 ：

(1)破坏请求和保持条件：在系统中不允许进程在已获得某种资源的情况下，申请其他资源，即要想出一个办法，阻止进程在持有资源的同时申请其它资源。

方法一：在所有进程开始运行之前，必须一次性的申请其在整个运行过程中所需的全部资源，这样，该进程在整个运行期间便不会再提出资源请求，从而破坏了“请求”条件。系统在分配资源时，只要有一种资源不能满足进程的需要，即使其它所需的各资源都空闲也不分配给该进程，而让该进程等待，由于该进程在等待期间未占用任何资源，于是破坏了“保持”条件。

方法二：要求每个进程提出新的资源申请前，释放它所占有的资源。这样，一个进程在需要资源S时，需要先把它先前占有的资源R释放掉，然后才能提出对S的申请，即使它很快又要用到资源R。

两种协议比较：第二种协议优于第一种协议，因为第一种协议会造成资源的严重浪费，使资源利用率大大的降低，也会由于占据大量资源导致其它进程的饥饿问题。

(2)破坏不可抢占条件：允许对资源实行抢夺。

方式一：如果占有某些资源的一个进程进行进一步资源请求被拒绝，则该进程必须释放它最初占有的资源，如果有必要，可再次请求这些资源和另外的资源。

方式二：如果一个进程请求当前被另一个进程占有的资源，则操作系统可以抢占另一个进程，要求它释放资源，只有在任意两个进程的优先级都不相同的条件下，该方法才能预防死锁。

(3)破坏循环等待条件

对系统所有资源进行线性排序并赋予不同的序号，这样我们便可以规定进程在申请资源时必须按照序号递增的顺序进行资源的申请，当以后要申请时需检查要申请的资源的编号大于当前编号时，才能进行申请。


**检测死锁**

```bash
jstack <pid>
```

或用jdk自带工具 jconsole





#### volatile 和 synchronized

`volatile`和`synchronized`是Java中用于处理并发编程的两个关键字，它们在处理多线程访问共享变量时有不同的用途和机制。下面详细介绍它们的特点、使用场景和区别。

##### `volatile`

`volatile`关键字用于修饰变量，保证了变量在多个线程之间的可见性和有序性。它具有以下特点：

1. **可见性**：当一个线程修改了`volatile`变量的值，新值对于其他线程立即可见。
2. **禁止重排序**：禁止编译器和CPU对其进行指令重排序，确保代码的执行顺序与程序的书写顺序一致。

**使用场景**

`volatile`适用于轻量级的状态标志变量或一读多写的场景。例如：

```java
java
Copy code
public class VolatileExample {
    private volatile boolean flag = false;

    public void writer() {
        flag = true;
    }

    public void reader() {
        if (flag) {
            // 执行某些操作
        }
    }
}
```

在上述示例中，当一个线程调用`writer()`方法时，其他线程调用`reader()`方法时能够立即看到`flag`的变化。

**局限性**

- 不能保证原子性：对`volatile`变量的操作不具备原子性，如复合操作（自增、自减等）无法保证线程安全。
- 不适用于复杂的同步场景：对于更复杂的同步需求，需要使用`synchronized`或其他同步机制。

##### `synchronized`

`synchronized`关键字用于在多个线程之间同步访问共享资源，确保互斥访问和线程之间的可见性。它具有以下特点：

1. **互斥性**：同一时刻只有一个线程能够持有`synchronized`锁，其他线程需要等待。
2. **可见性**：释放锁之前，线程对共享变量的修改对于之后获得同一锁的线程是可见的。

使**用场景**

`synchronized`适用于保护临界区、实现线程安全的复杂操作。例如：

```java
java
Copy code
public class SynchronizedExample {
    private int count = 0;

    public synchronized void increment() {
        count++;
    }

    public synchronized int getCount() {
        return count;
    }
}
```

在上述示例中，`increment()`方法和`getCount()`方法都被`synchronized`关键字修饰，保证了线程安全。

**区别**

1. **可见性**：
   - `volatile`：保证变量的可见性，但不保证操作的原子性。
   - `synchronized`：保证代码块内所有变量的可见性，同时保证互斥访问。
2. **互斥性**：
   - `volatile`：不提供互斥性，多个线程可以同时访问`volatile`变量。
   - `synchronized`：提供互斥性，同一时刻只有一个线程可以执行被`synchronized`修饰的代码块或方法。
3. **适用场景**：
   - `volatile`：适用于简单的状态标志和一读多写的场景，不适用于复合操作或复杂的同步场景。
   - `synchronized`：适用于保护临界区，确保复杂操作的线程安全。

**总结**

- 使用`volatile`关键字时，可以确保共享变量在多个线程之间的可见性和有序性，但不能保证操作的原子性。
- 使用`synchronized`关键字时，可以确保代码块或方法的互斥访问和变量的可见性，适用于需要确保复杂操作线程安全的场景。





### JVM

#### JVM内存模型

Java虚拟机（JVM）的内存模型是指JVM在运行Java程序时，如何在内部管理和分配内存的结构。理解JVM内存模型对于编写高效和优化的Java程序非常重要，它也帮助开发者避免内存泄漏和其他内存相关的问题。以下是JVM内存模型的主要组成部分：

1. 堆（Heap）

- **定义**：堆是JVM内存中最大的一块，也是JVM管理的主要内存区域，用于存放Java应用创建的对象实例和数组。几乎所有的对象实例都在这里分配内存。
- **特点**：堆是在虚拟机启动时创建的，是垃圾收集器管理的主要区域，因此也被称为"垃圾收集堆"（Garbage-Collected Heap）。

2. 方法区（Method Area）

- **定义**：方法区是所有线程共享的内存区域，用来存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。
- **特点**：从Java 8开始，传统的永久代（PermGen）被元空间（MetaSpace）所取代。

3. 程序计数器（Program Counter Register）

- **定义**：程序计数器是一小块内存空间，它可以看作是当前线程所执行的字节码的行号指示器。每个线程都有一个独立的程序计数器，线程私有。
- **特点**：这块内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。

4. 虚拟机栈（Java Virtual Machine Stacks）

- **定义**：每个线程私有，生命周期和线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。
- **特点**：每个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。

5. 本地方法栈（Native Method Stack）

- **定义**：本地方法栈与虚拟机栈发挥的作用非常相似，区别是虚拟机栈为执行Java方法（也就是字节码）服务，而本地方法栈则为Native方法服务。
- **特点**：在某些JVM实现中，本地方法栈和虚拟机栈是合二为一的。

垃圾回收

- **作用**：主要发生在堆内存中，目的是回收程序中不再使用的对象所占用的内存空间，确保内存的有效利用。
- **机制**：包括标记-清除、复制、标记-整理等算法。

总结

理解JVM的内存模型对于优化Java应用程序，避免内存溢出、内存泄漏等问题至关重要。开发者可以通过调整JVM的启动参数来优化内存使用，例如调整堆大小、选择合适的垃圾收集器等。




在 Java 中，堆（Heap）是用于存储对象实例和数组的内存区域，是 Java 虚拟机（JVM）运行时数据区域之一。堆内存管理是 JVM 的垃圾回收器的核心功能之一，主要涉及对象的分配、使用和释放。

##### 堆内存管理过程

1. **对象分配**：
   - 当应用程序创建新的对象时，JVM 在堆中分配内存空间来存储对象的数据。
   - 堆内存一般被划分为新生代和老年代两部分，其中新生代主要用于存储新创建的对象，而老年代主要用于存储长期存活的对象。
2. **垃圾回收**：
   - 当对象不再被引用时，Java 垃圾回收器会检测并回收这些无用对象所占用的内存空间，使其能够被重新利用。
   - 垃圾回收器通常会根据对象的存活周期将堆内存划分为不同的区域，并使用不同的回收算法来处理这些区域中的垃圾对象。
3. **内存分配策略**：
   - 在堆中分配内存时，通常使用指针碰撞（Bump Pointer）或空闲列表（Free List）等分配策略来管理可用内存空间。
4. **内存释放**：
   - 在进行垃圾回收时，无用对象所占用的内存空间会被释放，并加入到可用内存池中，以供后续对象分配使用。

**堆内存管理的优化**

1. **对象生命周期分析**：
   - 通过分析对象的生命周期，识别出长期存活的对象，以便将其分配到老年代中，从而减少新生代的垃圾回收频率。
2. **分代垃圾回收**：
   - 将堆内存分为不同的代（如新生代、老年代），使用不同的回收算法和策略来处理不同代中的对象，以提高垃圾回收的效率。
3. **并发和并行垃圾回收**：
   - 使用并发和并行的垃圾回收算法，充分利用多线程和多核处理器的优势，提高垃圾回收的并发性和吞吐量。
4. **空间压缩**：
   - 对于老年代中的内存碎片问题，可以通过垃圾回收器的空间压缩功能来整理内存空间，从而减少内存碎片化，提高内存利用率。





#### 垃圾回收

##### 垃圾回收的时机

JVM不提供固定时间表进行垃圾回收。相反，垃圾回收的触发基于堆内存的使用情况。常见的触发条件包括：

- 堆内存快满时。
- 老年代（Old Generation）内存不足时。
- System.gc() 方法被显式调用时（注意，这通常是不推荐的，因为它只是向JVM发出垃圾回收的建议，而不是强制性指令）。
- JVM进行了优化决策，基于内部指标认为进行GC是合适的时机。

##### 垃圾回收算法

1. **标记-清除（Mark-Sweep）**

- **标记阶段**：标记所有从根集合（如线程栈、静态字段等）可达的对象。
- **清除阶段**：回收所有未被标记的对象所占用的空间。
- **问题**：标记-清除算法执行后可能会留下大量空洞，导致内存碎片化。

2. **复制（Copying）**

- **工作原理**：将可用内存分为两个半区。任何时候只使用其中一个半区。当进行垃圾回收时，JVM会将当前半区中的活动对象复制到另一半区，然后清理正在使用的半区的所有对象。
- **优点**：减少碎片化，复制过程同时完成了新旧对象的排序。
- **缺点**：只能使用堆内存的一半，不太适用于对象存活率高的场景。

3. **标记-整理（Mark-Compact）**

- **工作原理**：与标记-清除类似，但在清除阶段，它不仅仅回收未被标记的对象，还将所有存活的对象压缩到堆的一端，以避免内存碎片化。
- **优点**：解决了内存碎片问题，使得程序运行更加高效。

4. **分代收集（Generational Collection）**

- **工作原理**：Java堆分为新生代（Young Generation）和老年代（Old Generation）。大部分新创建的对象首先放在新生代，新生代使用复制算法，因为大部分新生对象“朝生夕死”。只有经过多次GC仍然存活的对象，才会被移动到老年代，老年代通常使用标记-清除或标记-整理算法。
- **优点**：利用了对象的生命周期特性，提高了垃圾回收的效率。

##### 死亡对象判断方法

1. **引用计数（Reference Counting）**
   - **原理**：每个对象包含一个引用计数器，每当有一个引用连接到对象时，计数器值增加，当引用失效时，计数器值减少。当对象的引用计数为0时，该对象被视为不再使用。
   - **优点**：简单，回收延迟小。
   - **缺点**：无法解决循环引用问题，即两个或多个对象相互引用，即使它们已不可达也无法被回收。
2. **可达性分析（Reachability Analysis）**
   - **原理**：从一组称为根的对象（通常是活跃线程的局部变量、静态字段等）开始，沿着对象图的引用关系向下搜索，能够到达的对象被认为是活动的；反之，无法到达的对象认为是不可达的，即可回收的。
   - **优点**：能够解决引用计数法中的循环引用问题。
   - **缺点**：需要停顿程序执行（Stop-the-World），可能引发较长时间的暂停。







### 锁

<img src="https://pic4.zhimg.com/80/v2-f51a9f072bf5a8054fa78acdb15126cb_1440w.jpg" style="zoom: 67%;" />

##### **乐观锁 VS 悲观锁**

乐观锁与悲观锁是一种广义上的概念，体现了看待线程同步的不同角度。在Java和数据库中都有此概念对应的实际应用。

先说概念。对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。

而乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。

乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。

- 悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。
- 乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。

##### **公平锁 VS 非公平锁**

公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。

非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。



##### **共享锁 VS 排他锁**

排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。

共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。

独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。



#### AQS

**核心组成**

1. **同步状态（State）**
   - AQS定义了一个`volatile int`状态（state）来表示同步状态，这个状态的解释取决于实现的同步器。例如，在一个互斥锁中，状态可能是0（未锁定）和1（锁定）。
2. **等待队列（Wait Queue）**
   - 当线程尝试获取同步状态失败时，这些线程会被封装成节点（Node）并被加入到一个类型为FIFO的等待队列中。每个节点持有一个特定的线程引用，以便能够进行调度和管理。

**操作方法**

AQS定义了几个核心方法来管理其状态和队列，其中主要包括：

- `acquire(int arg)`: 在独占模式下获取对象状态。
- `release(int arg)`: 在独占模式下释放对象状态。
- `acquireShared(int arg)`: 在共享模式下获取对象状态。
- `releaseShared(int arg)`: 在共享模式下释放对象状态。

这些方法内部会调用自定义的方法来尝试获取或释放资源：

- `tryAcquire(int arg)`
- `tryRelease(int arg)`
- `tryAcquireShared(int arg)`
- `tryReleaseShared(int arg)`

这些方法需要由具体的同步器实现来定义具体的逻辑。

**同步器的实现**

AQS支持两种同步模式：独占模式和共享模式。

1. **独占模式（Exclusive Mode）**
   - 这种模式下，每次只有一个线程能持有同步状态。典型的实现是`ReentrantLock`。
2. **共享模式（Shared Mode）**
   - 允许多个线程同时获取同步状态。典型的实现有`Semaphore`、`CountDownLatch`、`ReadWriteLock`的读锁。

**典型应用**

1. **ReentrantLock**
   - 基于AQS的独占锁实现，支持公平锁和非公平锁。
2. **CountDownLatch**
   - 基于AQS的共享锁实现，允许一个或多个线程等待直到在其他线程中进行的一组操作完成。
3. **Semaphore**
   - 许可的同步器，基于AQS共享模式，控制同时访问某个特定资源的操作数量。
4. **ReadWriteLock**
   - 允许多个读取者共享访问，但写入者访问是独占的。



## Spring

### Spring 基础



#### bean是单例吗？

Spring Boot 推荐使用 java 配置完全代替 XML 配置，java 配置是通过 @Configration 和 @Bean 注解实现的。二者作用如下：

@Configration 注解：声明当前类是一个配置类，相当于 Spring 中的一个 XML 文件
@Bean 注解：作用在方法上，声明当前方法的返回值是一个 Bean

```java
@Configuration 
public class AppConfig { 
 @Bean 
 //表示一个方法产生了一个由Spring容器管理的bean
 public MyBean myBean() { 
 System.out.println("=======Bean1========");
 // 实例化、配置和返回 bean ... 
 } 
}
```

 **是单例。**单例的bean只有第一次创建新的bean 后面都会复用该bean，所以不会频繁创建对象。

**单例bean的优势**

由于不会每次都新创建新对象所以有一下几个性能上的优势：

1.减少了新生成实例的消耗

新生成实例消耗包括两方面，第一，spring会通过反射或者cglib来生成bean实例这都是耗性能的操作，其次给对象分配内存也会涉及复杂算法。

2.减少jvm垃圾回收

由于不会给每个请求都新生成bean实例，所以自然回收的对象少了。

3.可以快速获取到bean

因为单例的获取bean操作除了第一次生成之外其余的都是从缓存里获取的所以很快。



### IoC控制反转 和 AOP 面向切面编程

在Spring框架中，有一些常用的类和与IOC（控制反转）和AOP（面向切面编程）相关的重要类。以下是其中一些类的简要说明：

常用的类：
1. ApplicationContext：ApplicationContext 是 Spring 框架的核心类，用于管理和组织应用程序的对象（bean）。它是一个接口，提供了访问和配置 bean 的方法，以及在应用程序中发布事件的能力。

2. BeanFactory：BeanFactory 是 ApplicationContext 的底层接口，负责实例化、配置和组装 bean。它是 Spring 框架中的对象工厂，用于创建和管理 bean。

3. BeanDefinition：BeanDefinition 是一个对象，用于描述和定义一个 bean。它包含了 bean 的类名、属性、构造函数参数等信息，Spring 根据 BeanDefinition 来创建和配置 bean。

4. BeanPostProcessor：BeanPostProcessor 是一个接口，用于在 bean 的初始化前后进行扩展和自定义操作。通过实现该接口，可以在 bean 创建和初始化的过程中添加额外的逻辑。

5. Environment：Environment 是一个接口，用于获取应用程序的环境变量和属性配置。它提供了访问配置文件、命令行参数等的方法，以便于应用程序根据不同的环境进行配置。

与IOC和AOP相关的重要类：
1. @Autowired：@Autowired 是一个注解，用于自动装配 bean。通过在需要依赖注入的字段、构造函数或方法上使用 @Autowired 注解，Spring 能够自动将合适的 bean 注入到相应的位置。

2. @Component：@Component 是一个注解，用于将一个类标识为一个可被Spring容器管理的组件（bean）。通常用于标记业务逻辑类、数据访问类等。

3. @Aspect：@Aspect 是一个注解，用于定义切面。通过在类上使用 @Aspect 注解，可以将该类标记为一个切面，其中定义的通知将被应用到切点上。

4. JoinPoint：JoinPoint 是在 AOP 中表示方法或者连接点的对象。它提供了获取方法参数、方法签名、目标对象等信息的方法，用于在通知中获取和操作连接点的状态。

5. Advice：Advice 是在 AOP 中定义切面通知的接口。它包括前置通知（Before）、后置通知（After）、返回通知（AfterReturning）、异常通知（AfterThrowing）和环绕通知（Around）等。

6. ProxyFactoryBean：ProxyFactoryBean 是一个工厂 bean，用于创建代理对象。通过配置 ProxyFactoryBean，可以在运行时动态地创建代理对象，实现 AOP 的功能。

这些类是 Spring 框架中与IOC和AOP密切相关的一些重要类。它们提供了实现依赖注入、对象管理和切面编程的关键功能。



### Spring 事务

在Spring框架中，事务是指一组数据库操作（例如插入、更新、删除等）作为一个单一的工作单元进行执行的机制。事务提供了一种保证数据一致性和完整性的方式，即要么所有操作都成功执行，要么所有操作都被回滚到事务开始之前的状态。

Spring事务管理是基于AOP（面向切面编程）的方式实现的，它提供了对事务的声明式支持，使得开发者可以通过简单的配置来管理事务，而无需显式编写大量的事务管理代码。

使用Spring事务管理的关键是使用@Transactional注解或XML配置来标记事务边界。当标记了@Transactional注解的方法被调用时，Spring会自动创建一个事务，并在方法执行前开启事务，在方法执行后根据执行结果决定是提交事务还是回滚事务。

Spring事务管理提供了以下特性和好处：

1. 声明式事务管理：通过注解或XML配置来声明事务边界，使事务管理更加简单和方便。
2. 编程式事务管理：除了声明式事务管理外，Spring还提供了编程式的事务管理接口，允许在代码中精确控制事务的开始、提交和回滚。
3. 多种事务传播行为：Spring定义了多种事务传播行为，例如支持当前事务、新建事务、不使用事务等，以满足不同的业务需求。
4. 事务隔离级别：Spring支持设置事务的隔离级别，如读未提交、读已提交、可重复读、串行化等，确保数据的一致性和隔离性。
5. 异常处理和回滚：Spring事务管理可以根据不同的异常类型来决定是提交事务还是回滚事务，保证数据的完整性。
6. 跨数据源事务管理：Spring支持在多个数据源上进行分布式事务管理，保证不同数据库之间的数据一致性。

### 设计模式

工厂设计模式 : Spring 使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。

代理设计模式 : Spring AOP 功能的实现。

单例设计模式 : Spring 中的 Bean 默认都是单例的。

模板方法模式 : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。

包装器设计模式 : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。

观察者模式: Spring 事件驱动模型就是观察者模式很经典的一个应用。

适配器模式 : Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配Controller。



## 数据库

### MySQL

#### 适合建索引的情况

1、字段的数值有唯一性的限制
2、频繁作为WHERE查询条件的字段
3、经常GROUP BY和ORDER BY的列
4、UPDATE、DELETE的WHERE条件列
5、DISTINCT字段需要创建索引
6、多表JOIN连接操作时，创建索引注意事项
7、使用列的类型小的创建索引
8、使用字符传前缀创建索引
9、区分度高（散列性高）的列适合作为索引
10、使用最频繁的列放到联合索引的左侧
11、在多个字段都要创建索引的情况下，联合索引优于单值索引

#### 索引类型

Mysql目前主要有以下几种索引类型：FULLTEXT，HASH，BTREE，RTREE。

1. **FULLTEXT**

即为全文索引，目前只有MyISAM引擎支持。其可以在CREATE TABLE ，ALTER TABLE ，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR ，TEXT 列上可以创建全文索引。全文索引并不是和MyISAM一起诞生的，它的出现是为了解决WHERE name LIKE “%word%"这类针对文本的模糊查询效率较低的问题。

2. **HASH**

由于HASH的唯一（几乎100%的唯一）及类似键值对的形式，很适合作为索引。

HASH索引可以一次定位，不需要像树形索引那样逐层查找,因此具有极高的效率。但是，这种高效是有条件的，即只在“=”和“in”条件下高效，对于范围查询、排序及组合索引仍然效率不高。

3. **BTREE**

BTREE索引就是一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口root开始，依次遍历node，获取leaf。这是MySQL里默认和最常用的索引类型。

4. **RTREE**

RTREE在MySQL很少使用，仅支持geometry数据类型，支持该类型的存储引擎只有MyISAM、BDb、InnoDb、NDb、Archive几种。相对于BTREE，RTREE的优势在于范围查找。ps. 此段详细内容见此片博文：Mysql几种索引类型的区别及适用情况



**为什么Mysql使用B+树而非B树作索引**

1. B+树非叶子节点不存在数据只存索引，B树非叶子节点存储数据。
2. B+树查询效率更高。B+树使用双向链表串连所有叶子节点，区间查询效率更高（因为所有数据都在B+树的叶子节点，扫描数据库 只需扫一遍叶子结点就行了），但是B树则需要通过中序遍历才能完成查询范围的查找。
3. B+树查询效率更稳定。B+树每次都必须查询到叶子节点才能找到数据，每次查找的路径长度相同，而B树查询的数据不一定在叶子节点，会造成查询的效率的不稳定。
4. B+树的磁盘读写代价更小。B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B树更小，通常B+树矮更胖，高度小查询产生的I/O更少

**B+树的设计考虑到了磁盘的存储和读取特性，使其特别适合用于数据库索引：**

1. **减少磁盘寻道**： 由于B+树的非叶子节点只用于索引，并不实际存储数据（即不涉及数据的具体内容），这使得这些节点可以更小，从而在同一个磁盘块上存储更多的索引节点。这种结构减少了为了到达指定数据而需要的磁盘寻道次数。
2. **优化数据的顺序访问**： B+树的所有叶节点通过指针相连，并且包含实际的数据记录。这种设计使得一旦到达任一叶节点，顺序访问其他叶节点变得非常高效，因为它们在物理存储上通常也是顺序存放的。这极大地利用了磁盘顺序读取的高效性，特别是在执行范围查询时。
3. **高效的查找性能**： B+树的结构确保了查找操作具有相对稳定的性能，因为从根节点到任何叶节点的路径长度相同。这意味着每次查找都需要相同数量的磁盘读取操作，提高了预测性和一致性。
4. **利用磁盘预读**： 现代操作系统和磁盘控制器通常会采用预读技术，即在访问第一个磁盘块时，系统会预测接下来的访问模式，并预先将连续的磁盘块加载到内存中。由于B+树的叶节点是顺序连接的，这一特性可以被数据库系统用来提升读取效率。





#### MVCC和存储架构

1. MVCC（多版本并发控制）：
   - MVCC是MySQL在并发访问下实现事务隔离性的一种机制。它通过在每个数据行上保存多个版本，使得多个事务可以同时读取和修改同一数据行，而不会相互干扰。
   - 在MVCC中，每个事务在读取数据时会看到一个一致性的快照，这个快照是根据事务开始时间和数据行的版本信息来确定的。这样可以实现读取一致性，同时避免了读取操作对写入操作的阻塞。
   - 当事务进行修改时，会创建一个新的数据版本，并将其关联到事务的ID上。其他事务仍然可以读取原始版本的数据，直到新版本提交。
   - MVCC对于读多写少的场景非常适用，可以提高数据库的并发性能。
2. 存储架构：
   - MySQL的存储架构主要包括逻辑存储和物理存储两个层次。
   - 逻辑存储：逻辑存储是指通过数据库对象（如表、索引、视图）来组织和管理数据。逻辑存储包括表空间、段、区、页等概念，用于管理和组织数据对象。
   - 物理存储：物理存储是指实际将数据存储在磁盘上的方式。MySQL使用了InnoDB、MyISAM等存储引擎来管理物理存储。每个存储引擎都有自己的存储格式和数据结构，如InnoDB使用B+树来组织和存储数据。
   - 存储架构的选择会对数据库的性能、事务支持、并发控制等方面产生影响。不同的存储引擎有不同的特点和应用场景，开发者可以根据实际需求选择适合的存储引擎。



#### 分库分表之后**,id** 主键如何处理?

在进行分库分表操作后，处理主键尤其是ID主键是一个重要且需要特别注意的问题。由于数据被分散到多个库和表中，需要确保每条记录的ID仍然唯一，不能出现冲突。这里有几种常见的方法来处理分库分表后的ID主键问题：

1. UUID（Universally Unique Identifier）

使用UUID作为主键是一种简单且常用的方法，因为UUID可以保证在全局的唯一性。UUID生成的ID是基于多种因素计算得到的128位长的数字，其生成不依赖于数据库，因此非常适用于分布式系统。UUID的缺点是比较长，占用存储空间较多，且不便于进行排序。

2. 自增序列与分片键结合

在某些情况下，可以继续使用自增ID，但需要结合分片键来保证全局唯一。通常，每个数据库实例可以设置一个不同的起始值和相同的增长步长，或者使用不同的增长步长。

- **例子**：假设有5个数据库实例，可以设置第一个数据库的ID从1开始，每次增加5（1, 6, 11...），第二个数据库的ID从2开始，每次增加5（2, 7, 12...），以此类推。

3. 分布式ID生-成器

使用专门的分布式ID生成系统也是一个很好的选择，例如Twitter的Snowflake算法。这类算法能够生成短数字ID，并保证高并发环境下的唯一性和顺序性。

- **Snowflake**：这个算法生成一个64位的ID，其中包含时间戳、数据中心标识、机器标识和序列号。时间戳确保了顺序性，数据中心和机器标识确保了ID在不同服务器之间的唯一性，序列号则处理同一时间戳内的并发冲突。

4. 数据库自带的全局ID功能

有些数据库系统提供了全局ID生成的功能，如MySQL的auto_increment_increment和auto_increment_offset配置，这可以在多个实例间生成唯一的自增ID。

5. 客户端ID生成

在某些架构中，ID生成可以由应用客户端来完成，客户端可以使用组合键（如用户ID或其他业务标识与时间戳的组合）、GUID/UUID或通过调用分布式ID生成服务来实现。

在选择具体方案时，需要考虑系统的规模、并发量、可维护性以及业务的具体需求。每种方法都有其优缺点，需要根据实际情况进行权衡。通常在设计初期就需要确定ID生成策略，以避免将来在扩展或维护时遇到问题。



#### 乐观锁和悲观锁


在MySQL中，乐观锁和悲观锁是用来处理并发控制的两种机制，主要用于管理数据库中数据的一致性和完整性。这两种锁的选择依赖于你对系统操作中冲突发生的预期。

**悲观锁（Pessimistic Locking）**

悲观锁的核心思想是“总假设最坏的情况”，即总是假设会有其他的事务来对数据进行修改，从而在数据处理前就加锁，以防止其他事务对数据进行修改。悲观锁通常通过数据库提供的锁机制实现。

```sql
BEGIN; -- 开始事务

-- 通过SELECT ... FOR UPDATE语句加锁，锁定特定的行
SELECT * FROM accounts WHERE account_id = 101 FOR UPDATE;

-- 更新操作
UPDATE accounts SET balance = balance + 100 WHERE account_id = 101;

COMMIT; -- 提交事务
```

在这个例子中，`SELECT ... FOR UPDATE` 将对选中的行加上排他锁（X锁）。在事务提交之前，其他任何尝试锁定这些行的事务都将被阻塞。

**乐观锁（Optimistic Locking）**

乐观锁是一种在数据库中不常用真正的锁机制，而是基于数据版本控制（如版本号或时间戳）的方法来处理数据并发。乐观锁假设多个事务之间不会发生冲突，只在数据提交时检查在读取数据后是否有其他事务已经修改了数据。

**SQL示例**： 假设有一个`accounts`表，其中包括`balance`和`version`字段。

```sql
-- 读取数据时记录版本号
SELECT balance, version FROM accounts WHERE account_id = 101;

-- 应用程序计算新的余额
-- 假设新余额计算后为1200

-- 更新数据时检查版本号是否改变
UPDATE accounts SET balance = 1200, version = version + 1 WHERE account_id = 101 AND version = 1;

```

如果`version`字段在读取后和更新前没有改变，说明没有其他事务修改过这条记录，更新操作可以成功执行。如果`version`不匹配，则说明在此期间其他事务已经修改了数据，更新操作将失败。

**适用场景**

- **悲观锁** 适用于高冲突环境，如银行账户余额的更新，这种情况下使用悲观锁可以避免数据不一致。
- **乐观锁** 适合于冲突较少的环境，例如，当并发访问主要是读取操作时，使用乐观锁可以减少锁的开销，提高系统性能。





#### 表锁和行锁

在数据库管理系统中，锁是用来控制多个事务对同一数据的并发访问的机制。锁可以保护数据的完整性和一致性，防止数据被多个并发事务同时修改导致的问题。在MySQL等关系数据库中，常见的两种锁机制是表锁和行锁，它们在不同的层面上提供数据访问的控制。

**表锁（Table Locks）**

表锁是数据库中最基本的锁策略，它会锁定整个表。这意味着当一个事务对表加锁后，其他事务必须等待前一个事务释放锁后才能对该表执行读写操作。

**优点**：

- 表锁的管理简单，开销小，不需要太多的内存和CPU资源。
- 在涉及大量数据的批处理操作时，表锁可能比行锁更有效，因为它避免了大量的锁定和解锁操作。

**缺点**：

- 并发性低，特别是在高并发的环境下，表锁会成为性能瓶颈。
- 可能会导致大量的阻塞和死锁。

**SQL示例**： 在MySQL中，可以显式地对表进行加锁：

```sql
LOCK TABLES table_name WRITE;
```

这会对`table_name`加上写锁，阻止其他任何读写操作。

**行锁（Row Locks）**

行锁是更细粒度的锁，它允许对数据库表中单独的行进行加锁。这种类型的锁可以最大化并发处理，因为它只锁定必须要处理的数据，而不是整个表。

**优点**：

- 提供高度的并发性，允许多个事务操作同一表的不同行。
- 减少了死锁的发生。

**缺点**：

- 管理成本高，因为维护行锁需要的内存和CPU资源比表锁多。
- 在处理大量数据的情况下，可能会导致性能下降，因为每一行都需要检查和设置锁。

**SQL示例**： 在支持行锁的数据库中，行锁通常是隐式进行的，如在InnoDB存储引擎中：

```sql
SELECT * FROM table_name WHERE id = 1 FOR UPDATE;
```

**适用场景**

- **表锁** 更适合于读多写少的场景，或者表数据量不大时的简单应用。
- **行锁** 更适合于高并发的写操作，或者需要高度事务安全性的复杂应用。



#### Mysql查询优化

1、使用索引优化查询

**使用场景**：当你的数据库表中有大量数据，而你需要频繁进行搜索查询时，索引是提高查询效率的关键。

**代码示例**：

```sql
-- 假设我们有一个员工表 employees
CREATE TABLE employees (
    id INT AUTO_INCREMENT,
    name VARCHAR(100),
    department_id INT,
    PRIMARY KEY (id)
);

-- 为department_id字段创建索引
CREATE INDEX idx_department ON employees(department_id);

-- 使用索引进行查询
SELECT * FROM employees WHERE department_id = 5;
```

**代码解释**：

第一步是创建一个包含**id**, **name**, **department_id**字段的**employees**表。

然后为**department_id**字段创建一个索引**idx_department**。这个操作会让基于**department_id**的查询更快。

最后，我们执行一个查询，利用创建的索引，从而提高查询效率。

2、优化查询语句

**使用场景**：避免使用高成本的SQL操作，如**SELECT** *，尽量指定需要的列，减少数据传输和处理时间。

**代码示例**：

```sql
-- 不推荐的查询方式
SELECT * FROM employees;

-- 推荐的查询方式
SELECT id, name FROM employees;
```

**代码解释**：

第一个查询语句使用了**SELECT** *，它会获取所有列，这在数据量大时非常低效。

第二个查询仅请求需要的**id**和**name**列，减少了数据处理的负担。

最近无意间获得一份阿里大佬写的刷题笔记，一下子打通了我的任督二脉，进大厂原来没那么难。这是大佬写的， 七千页的BAT大佬写的[刷题笔记](https://link.segmentfault.com/?enc=Lf2y17%2BJ5CRRI8M7BYyx1g%3D%3D.z6mj7tVIPVXWlBTmC%2BM6w2rcmbMcwL%2B7fTl9AqditES1Ofr7gZbGt3loIyCJaXv2)，让我offer拿到手软

3、使用查询缓存

**使用场景**：当相同的查询被频繁执行时，使用查询缓存可以避免重复的数据库扫描。

**代码示例**：

```sql
-- 启用查询缓存
SET global query_cache_size = 1000000;
SET global query_cache_type = 1;

-- 执行查询
SELECT name FROM employees WHERE department_id = 5;
```

**代码解释**：

通过设置**query_cache_size**和**query_cache_type**，我们启用了查询缓存。

当我们执行查询时，MySQL会检查缓存中是否已经有了该查询的结果，如果有，则直接返回结果，避免了重复的数据库扫描。

4、避免全表扫描

**使用场景**：当表中数据量巨大时，全表扫描会非常耗时。通过使用合适的查询条件来避免全表扫描，可以显著提高查询效率。

**代码示例**：

```sql
-- 假设我们需要查询员工表中特定部门的员工
-- 不推荐的查询方式，会导致全表扫描
SELECT * FROM employees WHERE name LIKE '%张%';

-- 推荐的查询方式
SELECT * FROM employees WHERE department_id = 3 AND name LIKE '%张%';
```

**代码解释**：

第一个查询使用了模糊匹配**LIKE**，但缺乏有效的过滤条件，可能导致全表扫描。

第二个查询在**name**字段的模糊匹配前，增加了对**department_id**的条件过滤，这样就可以先缩小查找范围，避免全表扫描。

5、使用JOIN代替子查询

**使用场景**：在需要关联多个表的复杂查询中，使用JOIN代替子查询可以提高查询效率。

**代码示例**：

```sql
-- 假设我们有一个部门表 departments
CREATE TABLE departments (
    id INT AUTO_INCREMENT,
    name VARCHAR(100),
    PRIMARY KEY (id)
);

-- 不推荐的子查询方式
SELECT * FROM employees WHERE department_id IN (SELECT id FROM departments WHERE name = 'IT');

-- 推荐的JOIN查询方式
SELECT employees.* FROM employees JOIN departments ON employees.department_id = departments.id WHERE departments.name = 'IT';
```

**代码解释**：

第一个查询使用了子查询，这在执行时可能效率较低，特别是当子查询或主查询的结果集较大时。

第二个查询使用了**JOIN**操作，这通常比子查询更有效，尤其是在处理大型数据集时。

6、合理分页

**使用场景**：在处理大量数据的列表展示时，合理的分页策略可以减少单次查询的负担，提高响应速度。

**代码示例**：

```sql
-- 假设我们需要分页显示员工信息
-- 不推荐的分页方式，尤其是当offset值很大时
SELECT * FROM employees LIMIT 10000, 20;

-- 推荐的分页方式，使用更高效的条件查询
SELECT * FROM employees WHERE id > 10000 LIMIT 20;
```

**代码解释**：

第一个查询使用了**LIMIT**和较大的偏移量**offset**，在大数据集上执行时会逐行扫描跳过大量记录，效率低下。

第二个查询通过在**WHERE**子句中添加条件来避免不必要的扫描，从而提高分页效率。

7、利用分区提高性能

**使用场景**：对于大型表，特别是那些行数以百万计的表，使用分区可以提高查询性能和数据管理效率。

最近无意间获得一份阿里大佬写的刷题笔记，一下子打通了我的任督二脉，进大厂原来没那么难。这是大佬写的， 七千页的BAT大佬写的[刷题笔记](https://link.segmentfault.com/?enc=4N1MF3jUrqOGdMFVhf6VZQ%3D%3D.s4YlbNjLVbWgUwwSiX3upNuPPY6Jpwh6GgdKYKHGGnNKw4Wg5gxspJtQdAc1ER%2FO)，让我offer拿到手软

**代码示例**：

```sql
-- 假设我们需要对一个大型的订单表 orders 进行分区
CREATE TABLE orders (
    order_id INT AUTO_INCREMENT,
    order_date DATE,
    customer_id INT,
    amount DECIMAL(10, 2),
    PRIMARY KEY (order_id)
) PARTITION BY RANGE ( YEAR(order_date) ) (
    PARTITION p2020 VALUES LESS THAN (2021),
    PARTITION p2021 VALUES LESS THAN (2022),
    PARTITION p2022 VALUES LESS THAN (2023)
);

-- 查询特定年份的订单
SELECT * FROM orders WHERE order_date BETWEEN '2021-01-01' AND '2021-12-31';
```

**代码解释**：

我们为**orders**表创建了基于**order_date**字段的年份范围分区。

查询特定年份的数据时，MySQL只会在相关分区中搜索，提高了查询效率。

8、利用批处理减少I/O操作

**使用场景**：在进行大量数据插入或更新时，批处理可以减少数据库的I/O操作次数，从而提高性能。

**代码示例**：

```sql
-- 批量插入数据
INSERT INTO employees (name, department_id)
VALUES 
    ('张三', 1),
    ('李四', 2),
    ('王五', 3),
    -- 更多记录
;

-- 批量更新数据
UPDATE employees
SET department_id = CASE name
    WHEN '张三' THEN 3
    WHEN '李四' THEN 2
    -- 更多条件
END
WHERE name IN ('张三', '李四', -- 更多名称);
```

**代码解释**：

在批量插入示例中，我们一次性插入多条记录，而不是对每条记录进行单独的插入操作。

在批量更新示例中，我们使用**CASE**语句一次性更新多条记录，这比单独更新每条记录更有效率。

9、使用临时表优化复杂查询

**使用场景**：对于复杂的多步骤查询，使用临时表可以存储中间结果，从而简化查询并提高性能。

**代码示例**：

```sql
-- 创建一个临时表来存储中间结果
CREATE TEMPORARY TABLE temp_employees
SELECT department_id, COUNT(*) as emp_count
FROM employees
GROUP BY department_id;

-- 使用临时表进行查询
SELECT departments.name, temp_employees.emp_count
FROM departments
JOIN temp_employees ON departments.id = temp_employees.department_id;
```

**代码解释**：

首先，我们通过聚合查询创建了一个临时表**temp_employees**，用于存储每个部门的员工计数。

然后，我们将这个临时表与部门表**departments**进行连接查询，这样的查询通常比直接在原始表上执行复杂的聚合查询要高效。

10、优化数据类型

**使用场景**：在设计数据库表时，选择合适的数据类型对性能有显著影响。优化数据类型可以减少存储空间，提高查询效率。

**代码示例**：

```sql
-- 原始表结构
CREATE TABLE example (
    id INT AUTO_INCREMENT,
    description TEXT,
    created_at DATETIME,
    is_active BOOLEAN,
    PRIMARY KEY (id)
);

-- 优化后的表结构
CREATE TABLE optimized_example (
    id MEDIUMINT AUTO_INCREMENT,
    description VARCHAR(255),
    created_at DATE,
    is_active TINYINT(1),
    PRIMARY KEY (id)
);
```

**代码解释**：

在原始表中，使用了**INT**和**TEXT**这样的宽泛类型，这可能会占用更多的存储空间。

在优化后的表中，**id**字段改为**MEDIUMINT**，**description**改为长度有限的**VARCHAR(255)**，**created_at**只存储日期，而**is_active**使用**TINYINT(1)**来表示布尔值。这样的优化减少了每行数据的大小，提高了存储效率。

11、避免使用函数和操作符

**使用场景**：在WHERE子句中避免对列使用函数或操作符，可以让MySQL更有效地使用索引。

**代码示例**：

```sql
-- 不推荐的查询方式，使用了函数
SELECT * FROM employees WHERE YEAR(birth_date) = 1980;

-- 推荐的查询方式
SELECT * FROM employees WHERE birth_date BETWEEN '1980-01-01' AND '1980-12-31';
```

**代码解释**：

在第一个查询中，使用**YEAR()**函数会导致MySQL无法利用索引，因为它必须对每行数据应用函数。

第二个查询直接使用日期范围，这样MySQL可以有效利用**birth_date**字段的索引。

12、合理使用正规化和反正规化

**使用场景**：数据库设计中的正规化可以减少数据冗余，而反正规化可以提高查询效率。合理平衡这两者，可以获得最佳性能。

**代码示例**：

```sql
-- 正规化设计
CREATE TABLE departments (
    department_id INT AUTO_INCREMENT,
    name VARCHAR(100),
    PRIMARY KEY (department_id)
);

CREATE TABLE employees (
    id INT AUTO_INCREMENT,
    name VARCHAR(100),
    department_id INT,
    PRIMARY KEY (id),
    FOREIGN KEY (department_id) REFERENCES departments(department_id)
);

-- 反正规化设计
CREATE TABLE employees_denormalized (
    id INT AUTO_INCREMENT,
    name VARCHAR(100),
    department_name VARCHAR(100),
    PRIMARY KEY (id)
);
```

**代码解释**：

在正规化设计中，**departments**和**employees**表被分开，减少了数据冗余，但可能需要JOIN操作来获取完整信息。

在反正规化设计中，**employees_denormalized**表通过直接包含部门信息来简化查询，提高读取性能，但可能会增加数据冗余和更新成本。







### Redis

#### Redis常见数据结构和应用场景

Redis是一种高性能的键值存储系统，支持多种数据结构和底层实现。以下是Redis中常见的数据结构和它们的底层实现以及相应的应用场景：

1. 字符串（String）：
   - 底层实现：Redis的字符串是简单的二进制安全的字符串，使用动态字符串实现。
   - 应用场景：字符串是最基本的数据结构，可以用于缓存、计数器、分布式锁等。

2. 列表（List）：
   - 底层实现：Redis的列表是一个双向链表，支持在两端进行元素的插入和删除操作。
   - 应用场景：列表可以用于实现消息队列、发布/订阅系统、最新消息排行等。

3. 哈希（Hash）：
   - 底层实现：Redis的哈希是一个键值对的集合，使用哈希表实现。
   - 应用场景：哈希可以用于存储对象的属性，如用户信息、商品信息等。

4. 集合（Set）：
   - 底层实现：Redis的集合是一个无序的字符串集合，使用哈希表实现。
   - 应用场景：集合可以用于实现唯一值的存储、好友关系的存储等。

5. 有序集合（Sorted Set）：
   - 底层实现：Redis的有序集合是一个有序的字符串集合，使用跳跃表和哈希表实现。
   - 应用场景：有序集合可以用于实现排行榜、计分系统、范围查询等。

Redis的底层实现使用了多种数据结构，如动态字符串、双向链表、哈希表、跳跃表等，以实现高效的数据存储和操作。应用场景广泛，包括缓存、消息队列、计数器、排行榜、实时统计、分布式锁等。由于其高性能和丰富的数据结构支持，Redis在许多领域得到了广泛应用。





#### Redis为什么这么快

Redis快的原因主要是两个：

- Redis 基于内存，内存的响应时间是 100 纳秒。 1 毫秒 = 1000000 纳秒
- 由于 Redis 是单线程的，所以采用 IO 多路复用的模型来处理大量的客户端连接。

#### IO多路复用







## 数据结构

### 查找

#### B树和B+树

**B-树的定义**

一棵m阶的B-树，或为空树，或为满足下列特性的m叉树：
（1）树中每个结点至多有m棵子树；
（2）若根结点不是叶子结点，则至少有两棵子树；
（3）除根之外的所有非终端结点至少有［m/2］棵子树；
（4）所有的叶子结点都出现在同一层次上，并且不带信息，通常称为失败结点（失败结点并不存在，指向这些结点的指针为空。引入失败结点是为了便于分析B-树的查找性能）；
（5）所有的非终端结点最多有m-1个关键字。

**B+树**

1. 有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据（没有data），只用来索引（指针p），所有数据都保存在叶子节点（data）。
2. **所有键值在叶子节点**：B+树的所有键值信息都存储在叶子节点中，并且叶子节点包含指向记录的指针。
3. **非叶子节点仅用于索引**：B+树的非叶子节点不存储实际的数据，只存储其子节点中的最大（或最小）键值，用于指导搜索方向。非叶节点也同时存在于子节点
4. **叶子节点形成链表**：B+树的叶子节点之间形成一个链表，使得全树的遍历变得非常高效，特别适合范围查询。
5. **高空间利用率**：由于B+树的非叶子节点不存储数据信息，可以存储更多的键，从而降低了树的高度。



## 计网

### 基础

#### HTTP状态码

- **1xx（信息性状态码）**：表示接收的请求正在处理。
- **2xx（成功状态码）**：表示请求正常处理完毕。
- **3xx（重定向状态码）**：需要后续操作才能完成这一请求。
- **4xx（客户端错误状态码）**：表示请求包含语法错误或无法完成。
- **5xx（服务器错误状态码）**：服务器在处理请求的过程中发生了错误。

#### 在浏览器中输入url的一个过程？

1. **URL解析**
   浏览器首先解析URL（统一资源定位符），以确定你想访问的资源的类型和位置。URL通常包含协议（如HTTP或HTTPS）、服务器地址（域名）、以及路径和查询字符串。

2. **DNS查找**
   为了找到该URL的服务器IP地址，浏览器需要进行DNS（域名系统）查找。如果DNS信息不在浏览器或操作系统的缓存中，浏览器会向配置的DNS服务器发送一个请求，将域名解析为IP地址。

3. **建立连接**
   一旦获得服务器的IP地址，浏览器会尝试与服务器建立连接：对于HTTP，这涉及到打开一个TCP连接。对于HTTPS，还需要在TCP连接的基础上进行TLS握手，以建立安全连接。

4. **发送HTTP请求**
   连接建立后，浏览器会构建一个HTTP请求，并通过TCP连接发送给服务器。这个请求包含了方法（如GET或POST）、所请求的页面的路径、以及一些头部信息（如用户代理信息、接受的内容类型等）。

5. **服务器响应**
   服务器接收并处理来自浏览器的请求后，会回送一个HTTP响应，其中包含了请求资源的状态信息（如HTTP 200 OK）、服务器类型、内容类型、内容长度以及请求的实际数据（如HTML文档）。

6. **渲染页面**
   浏览器接收到服务器的数据后，开始解析HTML文档，构建DOM（文档对象模型），解析CSS并应用样式，执行JavaScript代码。这个过程中可能会有额外的资源需要加载，如图片、CSS文件和JavaScript文件等，这些资源的加载也可能触发额外的DNS查找、连接建立和HTTP请求。



#### 三次握手和4次挥手-TCP

3次握手（Three-way handshake）和4次挥手（Four-way handshake）是TCP（传输控制协议）中建立和终止连接的重要机制。下面分别介绍这两个过程：

**3次握手（建立连接）**

3次握手的目的是在两个TCP主机之间建立一个可靠的连接。它涉及以下步骤：

1. SYN（同步）
   - 客户端发送一个SYN（同步序列编号）包到服务器，并进入SYN_SEND状态，等待服务器确认。
2. SYN+ACK（确认）
   - 服务器接收到SYN包后，必须确认客户的SYN（ACK）并同时自己发送一个SYN包，即SYN+ACK包，此时服务器进入SYN_RECV状态。
3. ACK（确认）
   - 客户端收到服务器的SYN+ACK包后，发送一个确认包ACK给服务器。发送完这个包后，客户端和服务器都进入ESTABLISHED状态，完成三次握手，连接建立成功。

**4次挥手（断开连接）**

当TCP连接的一方完成数据传输后，会执行4次挥手来断开连接。这个过程包括以下步骤：

1. FIN（终止）
   - 客户端发送一个FIN包，用来关闭客户到服务器的数据传送，客户端进入FIN_WAIT_1状态。
2. ACK（确认）
   - 服务器收到这个FIN包，发送一个ACK包给客户端，确认序号为收到序号加1。服务器进入CLOSE_WAIT状态。
3. FIN（终止）
   - 服务器关闭与客户端的连接，发送一个FIN给客户端。服务器进入LAST_ACK状态。
4. ACK（确认）
   - 客户端收到服务器的FIN包后，发送一个ACK包给服务器，然后进入TIME_WAIT状态。经过一段时间后，客户端关闭连接，服务器在收到这个ACK后也关闭连接。



#### TCP如何保证可靠

TCP（传输控制协议）是一种面向连接的协议，旨在提供可靠的数据传输服务。TCP通过以下几种机制来实现其可靠性：

1. 序列号（Sequence Number）

每个TCP段都包含一个序列号，用于标识该段在整个数据流中的位置。序列号有助于确保数据的有序传输和重组。接收方可以根据序列号正确地将收到的段重组为原始数据流，即使这些段是乱序到达的。

2. 确认机制（Acknowledgment）

TCP使用确认机制来确保数据的正确传输。每个接收方在收到数据段后都会发送一个确认（ACK），其中包含下一个预期数据段的序列号。发送方在发送数据段后等待确认，如果在一定时间内未收到确认，则会重新发送该数据段。

3. 重传机制（Retransmission）

如果发送方在规定的时间内没有收到某个数据段的确认，TCP将重新发送该数据段。这个时间间隔由一个可调整的定时器（通常称为RTO，重传超时）控制，基于网络往返时间（RTT）来动态调整。

4. 流量控制（Flow Control）

TCP通过滑动窗口机制进行流量控制，以避免发送方发送数据速度过快而导致接收方的缓冲区溢出。接收方在每个确认段中包含一个窗口大小（window size），指示当前可以接收的数据量。发送方根据这个窗口大小调整发送数据的速率。

5. 拥塞控制（Congestion Control）

TCP包含多个拥塞控制算法（如慢启动、拥塞避免、快速重传和快速恢复）来防止网络拥塞：

- **慢启动（Slow Start）**：初始时发送方以指数速度增加其发送窗口，直到达到网络容量或遇到丢包。
- **拥塞避免（Congestion Avoidance）**：当达到慢启动阈值时，窗口以线性速度增长，避免过度拥塞。
- **快速重传（Fast Retransmit）**：接收方在检测到段丢失时，通过重复发送三个确认段来通知发送方进行快速重传。
- **快速恢复（Fast Recovery）**：在快速重传后，发送方减少其发送窗口，然后线性增加窗口大小，以快速恢复正常发送速率。

6. 校验和（Checksum）

每个TCP段都包含一个校验和，用于检验数据在传输过程中是否损坏。发送方计算并填充校验和，接收方在收到数据后重新计算校验和以验证数据的完整性。如果校验和不匹配，则认为数据损坏，丢弃该段并等待重传。





## 计组



### 基础



#### 栈溢出一般发生在什么情况下

1. 无限递归或过深的递归；
2. 大量的局部变量：在函数中声明大量的局部变量，尤其是大型的数据结构（如大数组），也可能导致栈空间迅速耗尽，从而引发栈溢出。
3. 深层嵌套函数调用
4. 线程栈空间限制：在多线程程序中，每个线程通常都有一个固定大小的栈。如果线程执行的操作需要的栈空间超过了预分配的大小，就会发生栈溢出。



## 操作系统



### 进程和线程

#### 进程间通信

1. 管道pipe：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
2. 命名管道FIFO：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
3. 消息队列MessageQueue：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
4. 共享存储SharedMemory：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。
5. 信号量Semaphore：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
6. 套接字Socket：套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。
7. 信号 ( sinal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。



#### 阻塞


在计算机编程和系统设计中，"阻塞"指的是一种情况，其中某个操作（如I/O操作、网络通信或者数据锁等待）暂停了执行线程的进一步操作，直到某个特定的事件发生或者条件被满足。在这期间，执行线程无法进行其他工作，它会一直等待，直到被阻塞的操作完成。阻塞是一种常见的同步操作。

**阻塞的常见形式包括：**

1. **I/O 阻塞**：
   - 当程序执行输入输出操作时，如读写文件、网络请求或用户输入等，程序执行流会停止至I/O操作完成。例如，从硬盘读取数据或从网络下载文件时，线程将停止执行，直到数据完全被读取。
2. **网络阻塞**：
   - 在等待网络响应时，如HTTP请求或远程数据库操作，线程会暂停执行直到网络操作完成。这包括等待数据被发送到网络对方或等待接收来自对方的数据。
3. **同步阻塞**：
   - 当多个线程试图访问共享资源时，为了保证数据一致性和线程安全，某些操作可能需要线程等待锁的释放。例如，在并发编程中，如果一个线程持有一个锁，其他试图访问该锁保护资源的线程将会被阻塞，直到锁被释放。
4. **系统调用阻塞**：
   - 某些系统级调用也可能造成阻塞，如等待某个操作系统事件或条件变量。

**阻塞与非阻塞**

阻塞与非阻塞的概念常常用来描述调用或操作的性质：

- **阻塞调用**意味着调用者将等待操作完成后才继续执行，这期间调用者不能做其他事情。
- **非阻塞调用**则意味着调用者不需要等待操作完成即可继续执行。在非阻塞调用中，如果操作不能立即完成，调用就会立即返回一个状态标志，调用者可以决定后续操作，可能是立即重试、延后重试或执行其他任务。

**阻塞的缺点**

尽管阻塞操作简化了编程模型（特别是同步操作），但它们在资源利用效率和程序性能方面有明显的缺点，包括：

- **CPU资源利用低**：阻塞时，线程不能执行其他任务，可能导致CPU资源浪费。
- **响应性差**：用户界面或服务可能因等待阻塞操作而出现延迟，影响用户体验和系统效率。
- **扩展性限制**：在高负载情况下，阻塞模型可能导致系统处理能力急剧下降，因为大量线程被挂起等待操作完成。





## Linux

### 命令

**1、查找文件**

`find / -name filename.txt` 根据名称查找/目录下的filename.txt文件。

`find . -name "*.xml"` 递归查找所有的xml文件

`find . -name "*.xml" |xargs grep "hello world"` 递归查找所有文件内容中包含hello world的xml文件

`grep -H 'spring' *.xml` 查找所以有的包含spring的xml文件

`find ./ -size 0 | xargs rm -f &` 删除文件大小为零的文件

`ls -l | grep '.jar'` 查找当前目录中的所有jar文件

`grep 'test' d*` 显示所有以d开头的文件中包含test的行。

`grep 'test' aa bb cc` 显示在aa，bb，cc文件中匹配test的行。

`grep '[a-z]\{5\}' aa` 显示所有包含每个字符串至少有5个连续小写字符的字符串的行。

**2、查看一个程序是否运行**

`ps -ef|grep tomcat` 查看所有有关tomcat的进程

**3、终止线程**

`kill -9 19979` 终止线程号位19979的进程

**4、查看文件，**包含隐藏文件

```
ls -al
```

**5、当前工作目录**

```
pwd
```

**6、复制文件**

`cp source dest` 复制文件

`cp -r sourceFolder targetFolder` 递归复制整个文件夹

`scp sourecFile romoteUserName@remoteIp:remoteAddr` 远程拷贝

**7、创建目录**

```
mkdir newfolder
```

**8、删除目录**

`rmdir deleteEmptyFolder` 删除空目录

`rm -rf deleteFile` 递归删除目录中所有内容

**9、移动文件**

```
mv /temp/movefile /targetFolder
```

**10、重命名**

```
mv oldNameFile newNameFile
```

**11、切换用户**

```
su -username
```

**12、修改文件权限**

`chmod 777 file.java` file.java 的权限`-rwxrwxrwx`，r表示读、w表示写、x表示可执行

**13、压缩文件**

```
tar -czf test.tar.gz /test1 /test2
```

**14、列出压缩文件列表**

```
tar -tzf test.tar.gz
```

**15、解压文件**

```
tar -xvzf test.tar.gz
```

**16、查看文件头10行**

```
head -n 10 example.txt
```

**17、查看文件尾10行**

```
tail -n 10 example.txt
```

**18、查看日志类型文件**

`tail -f exmaple.log` 这个命令会自动显示新增内容，屏幕只显示10行内容的（可设置）。

**19、使用超级管理员身份执行命令**

`sudo rm a.txt` 使用管理员身份删除文件

**20、查看端口占用情况**

`netstat -tln | grep 8080` 查看端口8080的使用情况

**21、查看端口属于哪个程序**

```
lsof -i :8080
```

**22、查看进程**

`ps aux|grep java` 查看java进程

`ps aux` 查看所有进程

**23、以树状图列出目录的内容**

```
tree a
```

**24、文件下载**

```
wget http://file.tgz
curl http://file.tgz
```

**25、网络检测**

```
ping www.just-ping.com
```

**26、远程登录**

```
ssh userName@ip
```

**27、打印信息**

`echo $JAVA_HOME` 打印java home环境变量的值

**28、java 常用命令**

java javac jps ,jstat ,jmap, jstack







## 项目

### 实习项目

- 1.基于Qt&C++框架实现了视觉系统的硬件信息管理和连接，控制多机械臂/深度相机等硬件的多线程操作处理，以及硬件信息的存储读取。
- 2.基于OpenCV库实现了多种手眼标定算法，获取相机在机器人基坐标系下的位姿。
- 3.基于PCL库实现了RANSAC+体素滤波+直通滤波的点云处理，降采样并去除环境点云数据。
- 4.实现了基于OPTICS，DBSCAN，HDBSCAN的点云分割算法，以及SAC+ICP点云配准方法。
- 5.基于OSG库实现深度相机拍摄的点云数据和2D图像的界面中渲染。
- 6.完成了系统中多个模块的QML前端页面的编写。



整体的系统流程是：

1. 首先是根据机械臂和结构光相机的几个坐标系进行标定，得到相机坐标系转换为机械臂坐标系的矩阵。
2. 对环境点云滤除后进行点云分割，分割出一个一个的工件，然后获取得到分别的坐标，传送给机械臂进行路径规划后抓取。
3. 



### 裂缝

业务流程：无人机拍摄的高分辨率图像数据和视频数据，经由管理员进行上传后，对大图像进行分块，对未检测的分块图片数据运行检测算法。检测完成的信息会对维修人员进行通知。具体系统划分为多个服务：用户信息管理和权限分级、裂缝信息管理（多级分类、危险等级、大小、位置等信息）、Minio文件分片上传和存储服务。我主要负责，构建MySQL存储表设计，并通过redis存储高频访问信息。构建了项目的整体MVC架构，主要就是这几个管理模块的controller、serviceimplement、mapper层等具体内容。





#### 项目亮点

1. Minio



2. 异步调用



实现了对文件的分片上传、断点续传等服务，

如何实现分片：对于同一个uploadId，分片号（PartNumber）标识了该分片在整个文件内的相对位置。如果使用同一个分片号上传了新的数据，则OSS上该分片已有的数据将会被覆盖。



MD5标识uploadID



#### **哪些业务场景使用了redis：**

缓存常查询的数据如用户身份验证信息；
经常访问的裂缝数据；
用户手机验证码等一定时间内会过期的数据；
裂缝信息的一级分类，二级分类，三级分类等

用户身份验证信息（如 JWT tokens, session IDs）常常需要频繁访问，可以存储在 Redis 中以提高验证过程的速度。

**实施方法**:

- 当用户登录时，将其认证信息如 token 或 session ID 存储在 Redis 中。可以使用 token 或 session ID 作为键，用户的身份或权限信息作为值。
- 设置适当的过期时间，例如 session 可能在30分钟或1小时后过期。
- 每次用户请求时，都可以通过 Redis 快速验证用户的 token 或 session ID 的有效性。

```
javaCopy code// 示例：存储会话信息
String token = generateToken(user);
redisTemplate.opsForValue().set(token, userDetails, 1, TimeUnit.HOURS);
```

2. 经常访问的裂缝数据

裂缝数据如果被频繁访问，将其缓存可以减少对数据库的访问次数，提高数据检索速度。

**实施方法**:

- 在用户查询裂缝数据时，首先检查 Redis 缓存中是否存在该数据。
- 如果存在，则直接从 Redis 返回数据；如果不存在，则从数据库加载数据，然后将数据存储到 Redis 中，并设置合理的过期时间。
- 可以使用裂缝的 ID 或其他唯一标识符作为键。

```
javaCopy code// 示例：缓存裂缝数据
CrackData crackData = (CrackData) redisTemplate.opsForValue().get(crackId);
if (crackData == null) {
    crackData = database.getCrackData(crackId);
    redisTemplate.opsForValue().set(crackId, crackData, 6, TimeUnit.HOURS);
}
return crackData;
```

3. 用户手机验证码等一定时间内会过期的数据

手机验证码通常具有短暂的有效期限，适合存储在 Redis 中，因为 Redis 支持自动过期。

**实施方法**:

- 将验证码和手机号作为键值对存入 Redis，并设置验证码的过期时间（如5分钟）。
- 用户提交验证码进行验证时，可以快速检查其有效性。

```
javaCopy code// 示例：存储验证码
redisTemplate.opsForValue().set(phoneNumber, code, 5, TimeUnit.MINUTES);
```

4. 裂缝信息的分类

如果裂缝信息的分类不经常改变，但需要频繁访问，可以缓存分类数据以提高访问速度。

**实施方法**:

- 将各级分类数据作为静态数据存储在 Redis 中。
- 可以将一级分类、二级分类和三级分类分别存储，或者将整个分类树作为一个对象存储。

```
javaCopy code// 示例：缓存分类数据
redisTemplate.opsForValue().set("crackCategories", categories);
```

#### **用到了线程池吗？**

##### **异步处理Minio上传的图片和视频数据，然后文件切片上传再合并**

- 文件切片：将一个大文件分割成多个小文件，每个小文件包含文件的一部分数据。
- 并行上传：同时上传多个小文件，提高上传速度。
- 文件合并：一旦所有的小文件上传完成，将它们合并成一个完整的文件。

在这个服务中，我们定义了一个名为 uploadFile 的方法，用于处理文件上传的请求。我们首先获取文件的大小，并根据文件大小计算出需要分割的文件片数。然后，我们创建一个线程池ExecutorService与**ThreadPoolExecutor**，并使用多个线程并行上传文件的不同部分。在每一个线程中，我们读取文件的一部分，并使用 MinIO 的 putObject 方法将其上传到指定的存储桶中。（这里用**ConcurrentHashMap**保存分片文件）
在所有文件部分上传完成后，我们需要调用 mergeFileParts 方法来合并文件的部分。这个方法使用 MinIO 的 completeMultipartUpload 方法来合并文件的部分。

```java
import io.minio.MinioClient;
import io.minio.PutObjectOptions;
import io.minio.errors.MinioException;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import org.springframework.web.multipart.MultipartFile;
import java.io.IOException;
import java.io.InputStream;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.StandardCopyOption;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
@Service
public class FileUploadService {
    @Autowired
    private MinioClient minioClient;
    private static final int THREAD_COUNT = 10;
    private static final ConcurrentHashMap<String, Integer> partMap = new ConcurrentHashMap<>();
    public void uploadFile(MultipartFile file) {
        String bucketName = "my-bucket";
        String objectName = file.getOriginalFilename();
        long fileSize = file.getSize();
        int partCount = (int) (fileSize / 1024 / 1024) + 1;
        partMap.put(objectName, partCount);
        ExecutorService executor = Executors.newFixedThreadPool(THREAD_COUNT);
        for (int i = 0; i < partCount; i++) {
            long start = i * 1024 * 1024;
            long end = (i + 1) * 1024 * 1024 - 1;
            if (i == partCount - 1) {
                end = fileSize - 1;
            }
            executor.execute(() -> {
                try {
                    InputStream fileStream = file.getInputStream();
                    Path tempFile = Files.createTempFile("temp", ".part");
                    try (InputStream is = fileStream) {
                        Files.copy(is, tempFile, StandardCopyOption.END_OF_FILE);
                    }
                    PutObjectOptions options = new PutObjectOptions(end - start + 1, PutObjectOptions.DEFAULT_CONTENT_TYPE);
                    options.setContentLength(end - start + 1);
                    minioClient.putObject(bucketName, objectName + "_" + i, tempFile.toFile(), start, end, options);
                    Files.deleteIfExists(tempFile);
                } catch (IOException | MinioException e) {
                    e.printStackTrace();
                }
            });
        }
        executor.shutdown();
        try {
            executor.awaitTermination(1, java.util.concurrent.TimeUnit.HOURS);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        // Merge file parts after upload
        mergeFileParts(objectName, partCount);
    }
    private void mergeFileParts(String objectName, int partCount) {
        minioClient.completeMultipartUpload(
                "my-bucket",
                objectName,
                new io.minio.GetObjectOptions().withRange(0, partCount * 1024 * 1024 - 1),
                partMap.get(objectName)
        );
    }
}

```

1. **初始化 Minio 客户端**：
   - `minioClient` 是通过 Spring 的自动装配 (`@Autowired`) 注入的，用于与 Minio 服务器交互。
2. **计算分块上传的数量**：
   - 文件大小通过 `file.getSize()` 获取，然后计算需要上传的块数 (`partCount`)。文件大小除以每块1MB（1024*1024字节），如果有余数则总块数加一。
3. **并发上传文件的每个部分**：
   - 使用固定大小（10线程）的线程池来并发上传文件的每个部分。对于每个部分，计算起始和结束字节位置，最后一块处理可能的余数。
   - 对于每块文件，首先从原始文件中读取相应的部分，存储到临时文件中，然后上传这个临时文件到 Minio。上传完成后删除临时文件。
4. **异常处理**：
   - 捕获 `IOException` 和 `MinioException` 异常，打印错误堆栈。这可能包括网络错误、文件操作错误等。
5. **线程池的关闭和等待**：
   - 上传任务提交后，通过 `executor.shutdown()` 关闭线程池，并通过 `executor.awaitTermination()` 等待最长一小时以完成所有上传任务。
6. **文件块合并**：
   - 调用 `mergeFileParts` 方法，这里假设有一个方法通过 Minio 客户端将所有上传的部分合并为一个完整文件。这部分代码实际上有误，因为 Minio SDK 的 `completeMultipartUpload` 方法并不接受这样的参数，且通常需要在上传每个部分后收集特定的上传 ID，这里的逻辑需要根据实际的 Minio SDK 文档进行调整。

**使用 MinIO 而不是本地存储主要有以下几个原因：**

1. **可扩展性**: MinIO 提供了高度可扩展的存储解决方案，可以轻松处理从小到大的数据需求。相比之下，本地存储的扩展性受到硬件限制，当数据量增长时，可能需要物理扩容，这既费时又费力。
2. **高可用性**: MinIO 支持多副本和数据冗余，可以保证数据在硬件故障时的可用性和持久性。而单一的本地存储在硬件出现问题时，数据恢复可能会更复杂和不可靠。
3. **分布式架构**: MinIO 可以配置为分布式系统，数据可以跨多个服务器和地理位置存储，这样可以提高数据的访问速度和容灾能力。本地存储通常局限于单一位置。
4. **对象存储特性**: MinIO 是一个对象存储服务，适用于存储非结构化数据如图片、视频等，它提供了丰富的API（如S3兼容API）用于管理数据。而本地存储通常功能较为基础，可能不支持这些高级特性。
5. **维护和管理**: MinIO 的维护和扩展通常比本地存储更简单，尤其是在云环境中，可以通过自动化工具来管理存储资源。对于大规模部署，这一点尤其重要。

总之，选择 MinIO 或本地存储取决于具体的业务需求、预算和数据管理策略。如果需要高可用性、易于扩展和管理的存储解决方案，MinIO 是一个很好的选择。





##### **异步处理图像的裂缝识别，异步运行检测服务**

CompletableFuture + ThreadPoolExecutor 

```java
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.scheduling.annotation.EnableAsync;
import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;

@Configuration
@EnableAsync
public class AsyncConfig {
@Bean(name = "taskExecutor")
    public ThreadPoolTaskExecutor taskExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(10);  // 核心线程数
        executor.setMaxPoolSize(20);   // 最大线程数
        executor.setQueueCapacity(50); // 队列大小
        executor.setThreadNamePrefix("MyTaskExecutor-");
        executor.setWaitForTasksToCompleteOnShutdown(true);
        executor.setAwaitTerminationSeconds(60);
        executor.initialize();
        return executor;
    }
}
```


```java
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;
import java.awt.image.BufferedImage;
import java.util.concurrent.CompletableFuture;

@Service
public class ImageRecognitionService {

    @Autowired
    private CrackDetectionService detectionService;  // 假设这是实现裂缝检测的服务

    @Async("taskExecutor")
    public CompletableFuture<String> detectCracks(BufferedImage image) {
        try {
            String result = detectionService.detect(image);  // 执行裂缝检测
            return CompletableFuture.completedFuture(result);
        } catch (Exception e) {
            CompletableFuture<String> future = new CompletableFuture<>();
            future.completeExceptionally(e);
            return future;
        }
    }
}
```

******************************************************************************

#### jwt + oauth2

j'wt：一旦用户登录，每个后续请求将包括JWT，从而允许用户访问该令牌允许的路由，服务和资源

JWT 的工作原理如下：

1. 用户通过提供有效的身份凭证（例如用户名和密码）向服务器请求访问资源。
2. 服务器验证用户提供的凭证，并生成一个包含用户标识和其他声明的 JWT。
3. 服务器将 JWT 作为响应返回给客户端。
4. 客户端在后续请求中将 JWT 放入请求的头部或其他位置，以便服务器进行验证和授权。
5. 服务器收到请求后，从 JWT 中提取信息，并根据其中的声明进行身份验证和授权。
6. 如果 JWT 通过验证，服务器向客户端返回请求的资源。

下面是基于 Spring Cloud Gateway + Spring Security OAuth2 + JWT 实现统一认证授权和鉴权的**开发过程：**

1. 设置认证服务器：搭建并配置一个独立的认证服务器，负责用户认证和颁发访问令牌。可以使用Spring Security OAuth2来实现认证服务器，配置用户存储、授权方式、令牌管理等。

2. 配置Spring Cloud Gateway：配置Spring Cloud Gateway作为API网关，用于接收和转发客户端的请求。需要配置路由规则、过滤器链、安全策略等。

3. 集成认证服务器和网关：在Spring Cloud Gateway中集成认证服务器，以实现认证和授权功能。可以使用Spring Security OAuth2的相关组件，如OAuth2ClientAuthenticationProcessingFilter和OAuth2AuthorizationFilter，来处理认证和授权逻辑。

4. JWT生成和验证：在认证服务器中生成JWT令牌，并在网关中进行验证。可以使用Spring Security的JwtTokenStore和JwtAccessTokenConverter来处理JWT的生成和验证。

5. 配置资源服务器：在API服务中配置资源服务器，用于验证访问令牌并控制访问权限。可以使用Spring Security OAuth2的资源服务器相关组件，如ResourceServerConfigurerAdapter和@PreAuthorize注解，来进行鉴权操作。

6. 前端集成：在前端应用中，需要实现用户登录和令牌管理的相关界面和逻辑。通过OAuth2协议与认证服务器进行交互，获取访问令牌，并在请求中附带令牌进行访问。

以上是基于Spring Cloud Gateway + Spring Security OAuth2 + JWT实现统一认证授权和鉴权的大致开发过程。具体实现时，需要根据项目需求和具体场景进行适配和配置。同时，还需注意安全性和性能方面的考虑，以确保系统的稳定和安全。


******************************************************************************

### 安卓项目

- 1.基于Agora SDK实现实时视频流的捕捉、处理和传输，支持多人在线视频。使用HandlerThread处理帧人像分割等耗时操作，确保视频数据的实时传输和渲染不受主线程UI更新的影响。
- 2.部署和调整最大预览分辨率和纹理视图配置，确保应用在不同设备上的兼容性和性能。
- 3.使用Android的Camera2 API实现视频捕获功能，并管理相机activity的生命周期。设计实现相机的回调函数，利用信号量机制控制相机资源的同步访问。
- 4.基于MobileNetV3-Unet网络，采用AISegment人像数据集为训练集，对全精度模型进行量化感知训练后，导出TFlite的8-bit量化模型并完成应用内的模型调用。
- 5.使用OpenGLES和GPUImage进行视频渲染，加速图像处理过程，提高渲染效率和响应速度。
- 还有就是判断当前端的处理算力，如果gpu性能不够的话 或者没有gpu 就将分割任务放到云上去做。

  Android 开发的四大组件分别是：活动（activity），用于表现功能；服务（service），后台运行服务，不提供界面呈现；广播接受者（Broadcast Receive），用于接收广播；内容提供者（Content Provider）



TextureView -> canvas -> draw Bitmap

1. ·使用BitmapFactory.Options的inBitmap属性
    从Android API 11（3.0 Honeycomb）开始，BitmapFactory.Options提供了inBitmap属性，允许复用已有的Bitmap对象来解码新的图片，前提是这两者的像素大小必须一致。
2. 创建一个Bitmap池
    在处理视频流或频繁更新的图片时，维护一个Bitmap池
3. 是一种更有效的方式。你可以创建一个集合来存储不再使用的Bitmap对象，并在需要新的Bitmap时从池中取出一个现成的，而不是新建一个。

  ```
  object BitmapPool {
   private val pool = Collections.synchronizedList(mutableListOf<Bitmap>())
  
   fun get(width: Int, height: Int, config: Bitmap.Config): Bitmap? {
       for (bitmap in pool) {
           if (bitmap.isMutable && bitmap.width == width && bitmap.height == height && bitmap.config == config) {
               pool.remove(bitmap)
               return bitmap
           }
       }
       return Bitmap.createBitmap(width, height, config)
   }
  
   fun release(bitmap: Bitmap) {
       pool.add(bitmap)
  
  
  
   }
  
   fun clear() {
       for (bitmap in pool) {
           bitmap.recycle()
       }
       pool.clear()
   }
  }
  ```

  

4. 在视频处理中重用Bitmap
    如果你正在处理视频流，你可以在一个固定数量的Bitmap对象之间循环使用，确保它们与视频帧的尺寸和配置匹配。











数据封装过程：
1.应用层准备数据，把数据交给传输层。
2.传输层把数据分段，将文件分成数据包，并标上顺序号，然后传给网络层，传输层的数据叫做数据段。
3.网络层给每一段加上地址（源IP地址，目标IP地址），把数据给数据链路层，网络层的数据叫做数据报。
4.数据链路层：
先判断:
使用自己的子网掩码，判断自己在哪个网段，然后使用自己的子网掩码，判断目标地址在哪个网段。a. 如果是同一个网段，使用ARP协议广播解析目标IP地址的MAC地址。
b. 如果不是一个网段，通过网关把数据包给路由器。然后把当前的MAC地址和下一跳的MAC地址添加在数据包后面，在数据包前面加上FCS（帧校验序列），把数据给物理层，数据链路层的数据叫数据帧。
5.物理层把数据链路层的数据帧变成数字信号（比特流），物理层的数据叫做比特流，就是0和1组成的序列。



中间的传输过程：
6.（如果有集线器）物理层把数据发给集线器，集线器传递比特流，加强信号，不做任何判断。（集线器和网线是同一级别的）
7.比特流被发送到交换机，交换机接收并存储比特流，查看目标MAC地址，选择出口（由哪个口转发出去），交换机能够看懂数据链路层添加的MAC地址，所以交换机是数据链路层的设备，是二层设备（第一层的物理层）。
8.交换机把比特流发送到路由器，路由器接收比特流，接收后去掉数据链路层的帧校验序列以及MAC地址，根据目标IP地址选择路径6出口。网卡重新包装数据包，路由器和下一个路由器之间如果使用的是PPP协议（点对点），因为使用了这个协议，所以不写源MAC地址，只写目标MAC地址为FF，变成比特流再往下传输。
9.下一个路由器接收到比特流，去掉MAC地址，如果IP地址是对的，根据数据包选择转发的路径，封装上目标MAC地址和当前MAC地址，变成比特流继续传输。错误的则丢掉数据包。
10.计算机接收到之后处理数据。



数据解封过程：
11.物理层接收到比特流，把比特流转换成数据帧给数据流层。
12.数据流层把打包数据时加入的两个MAC地址和FCS去掉，把数据包交给网络层。
13.网络层把数据包中的IP地址去掉，把剩余的数据段给传输层。
14.传输层把数据段的头去掉，把数据交给应用层。
15.应用层把收到的一段一段的数据再拼到一起，成为一块完整的数据。
