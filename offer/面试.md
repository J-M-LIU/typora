条件卷积代码示例

```
import torch
import torch.nn as nn
import torch.nn.functional as F

class GlobalConditionalConv2d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, 
                 lambda_set=[0.001, 0.01, 0.1], stride=1, padding=0):
        """
        全局参数化条件卷积
        Args:
            lambda_set (list): 预定义的λ值集合，例如[0.001, 0.01, 0.1]
        """
        super().__init__()
        self.lambda_set = lambda_set
        self.num_lambdas = len(lambda_set)
        
        # 标准卷积层
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, 
                            stride=stride, padding=padding, bias=False)
        
        # 参数生成网络 (全局共享参数)
        self.fc_scale = nn.Linear(self.num_lambdas, 1)  # 生成单个缩放因子
        self.fc_bias = nn.Linear(self.num_lambdas, 1)   # 生成单个偏置项

    def forward(self, x, lambda_idx):
        """
        Args:
            x: 输入特征图 [B, C, H, W]
            lambda_idx: λ的索引值 [B], 例如0表示使用lambda_set[0]
        """
        batch_size = x.size(0)
        
        # 生成独热编码 [B, num_lambdas]
        one_hot = F.one_hot(lambda_idx, num_classes=self.num_lambdas).float().to(x.device)
        
        # 生成全局缩放因子和偏置 [B, 1]
        scale = torch.log1p(torch.exp(self.fc_scale(one_hot)))  # softplus保证正数
        bias = self.fc_bias(one_hot)
        
        # 应用标准卷积 [B, C_out, H', W']
        base_output = self.conv(x)
        
        # 全局参数广播 [B, 1, 1, 1] -> [B, C_out, H', W']
        scale = scale.view(batch_size, 1, 1, 1)
        bias = bias.view(batch_size, 1, 1, 1)
        
        # 全局参数调整
        return scale * base_output + bias

# 测试用例
if __name__ == "__main__":
    # 超参数
    B, C_in, C_out = 4, 3, 64
    H, W = 256, 256
    kernel_size = 3
    
    # 初始化模块
    conv = GlobalConditionalConv2d(C_in, C_out, kernel_size, padding=1)
    
    # 生成测试输入
    x = torch.randn(B, C_in, H, W)
    lambda_indices = torch.randint(0, 3, (B,))  # 随机生成λ索引
    
    # 前向传播
    output = conv(x, lambda_indices)
    
    print(f"输入形状: {x.shape}")
    print(f"输出形状: {output.shape}")  # 预期: [4, 64, 256, 256]
    print(f"可训练参数数量: {sum(p.numel() for p in conv.parameters())}") 
    # 输出: 标准卷积参数 + (1+1)*3 = 3 * 64 * 3 * 3 + 6 = 1728 + 6 = 1734
```

