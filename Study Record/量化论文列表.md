

- **ICCV 2021 33/1611**

⏬Improving Neural Network Efficiency via **Post-training Quantization** with Adaptive Floating-Point
⏬Once **Quantization-Aware Training**: High Performance Extremely Low-bit Architecture Search
⏬Distance-aware Quantization
✅Improving **Low-Precision** Network Quantization via Bin Regularization - Xlinux 
✅MixMix: All You Need for **Data-Free Compression** Are Feature and Data Mixing

⏬Towards **Mixed-Precision** Quantization of Neural Networks via Constrained Optimization
⏬RMSMP: A Novel Deep Neural Network Quantization Framework with Row-wise Mixed Schemes and **Multiple Precisions**

⏬Cluster-Promoting Quantization with **Bit-Drop** for Minimizing Network Quantization Loss
⏬**Integer-arithmetic-only** Certified Robustness for Quantized Neural Networks
⏬**Selective Feature Compressio**n for Efficient Activity Recognition Inference
⏬Generalizable **Mixed-Precision** Quantization via Attribution Rank Preservation

ReCU: **Reviving the Dead Weights** in **Binary** Neural Networks
Deep Halftoning with Reversible **Binary** Pattern
Sub-bit Neural Networks: Learning to Compress and Accelerate **Binary** Neural Networks.

Online Multi-Granularity Distillation for **GAN Compression**
Online-trained Upsampler for Deep Low Complexity **Video Compression.** Dynamic Network Quantization for Efficient **Video** Inference. Motion Adaptive Pose Estimation from Compressed **Videos**
Product Quantizer Aware Inverted Index for Scalable **Nearest Neighbor Search**. Efficient Video Compression via Content-Adaptive **Super-Resolution**。 COMISR: Compression-Informed **Video Super-Resolution**
Self-supervised Neural Networks for Spectral Snapshot **Compressive Imaging**
Neural **Image Compression** via Attentional Multi-scale Back Projection and Frequency Decomposition. Learning Dual Priors for JPEG Compression Artifacts Removal
Self-supervised Domain Adaptation for Forgery Localization of **JPEG Compressed Images**.

### **ICCV 2019 23/1075**

⏬Adversarial Robustness vs. Model Compression, or Both? 
⏬A **Bayesian** Optimization Framework for Neural Network Compression
⏬Proximal Mean-Field for Neural Network Quantization
⏬Learning Filter Basis for Convolutional Neural Network Compression
✅HAWQ: **Hessian** AWare Quantization of Neural Networks With Mixed-Precision
✅Data-Free Quantization Through Weight Equalization and Bias Correction
✅Differentiable Soft Quantization: Bridging Full-Precision and Low-Bit Neural Networks.

Learned **Video Compression**
Fast Object Detection in Compressed **Video**
Neural Inter-Frame Compression for **Video** Coding
**Video Compression** With Rate-Distortion Autoencoders
Non-Local **ConvLSTM** for **Video Compression** Artifact Reduction
DSIC: Deep Stereo **Image Compression**
Variable Rate Deep **Image Compression** With a Conditional Autoencoder
Generative Adversarial Networks for Extreme Learned **Image Compression**
Deep Tensor ADMM-Net for Snapshot **Compressive Imaging**

### **ICCV 2017 9/621**

⏬Performance Guaranteed Network Acceleration via **High-Order Residual Quantization**
⏬Domain-Adaptive Deep Network Compression

Compressive Quantization for Fast Object Instance Search in **Videos**

------

### **NeurIPS 2022**

### **NeurIPS 2021 50/2334**

⏬BatchQuant: Quantized-for-all Architecture Search with Robust Quantizer
⏬**Post-Training Sparsity-Aware Quantization**
⏬Compressing Neural Networks: Towards Determining the Optimal Layer-wise Decomposition
VQ-GNN: A Universal Framework to Scale up **Graph Neural Networks** using **Vector Quantization**
AC/DC: Alternating Compressed/DeCompressed **Training** of Deep Neural Networks
S3^3: Sign-Sparse-Shift Reparametrization for Effective **Training** of **Low-bit** Shift Networks
⏬Qimera: **Data-free Quantization** with Synthetic Boundary Supporting Samples
⏬RED : Looking for Redundancies for **Data-Free Structured Compression** of Deep Neural Networks
✅Post-Training Quantization for **Vision Transformer**

Demystifying and Generalizing **BinaryConnect**
Learning Frequency Domain Approximation for **Binary** Neural Networks

Escaping Saddle Points with **Compressed SGD**
Asynchronous **Decentralized SGD** with Quantized and Local Updates
QuPeD: Quantized Personalization via Distillation with Applications to **Federated Learning**
DRONE: **Data-aware Low-rank** Compression for Large **NLP** Models.

Compressed **Video** Contrastive Learning
Deep Contextual **Video** Compression
Revisiting Discriminator in **GAN Compression**: A Generator-discriminator Cooperative Compression Scheme.

### **NeurIPS 2020 47/1898**

A Statistical Framework for **Low-bitwidth Training** of Deep Neural Networks
Adaptive **Gradient Quantization** for **Data-Parallel SGD**
⏬Searching for **Low-Bit Weights** in Quantized Neural Networks
⏬Hierarchical **Quantized Autoencoders**
⏬Robust Quantization: One Model to Rule Them All
⏬**Bayesian** Bits: Unifying Quantization and Pruning
⏬Universally Quantized Neural Compression
✅HAWQ-V2: **Hessian** Aware trace-Weighted Quantization of Neural Networks
✅FleXOR: **Trainable** Fractional Quantization

✅Rotated Binary Neural Network
Path Sample-Analytic Gradient Estimators for Stochastic **Binary** Networks.

ScaleCom: Scalable Sparsified Gradient Compression for **Communication-Efficient Distributed Trainin**
**Practical Low-Rank** Communication Compression in **Decentralized Deep Learning**
WoodFisher: Efficient **Second-Order Approximation** for Neural Network Compression
Position-based Scaled **Gradient** for Model Quantization and Pruning
A Statistical Framework for **Low-bitwidth Training** of Deep Neural Networks

Matrix Completion with Quantified Uncertainty through **Low Rank Gaussian Copula**
MiniLM: Deep Self-Attention Distillation for Task-Agnostic **Compression of Pre-Trained Transformers.**
Improving Inference for Neural **Image Compression**
High-Fidelity Generative **Image Compression**

### **NeurIPS 2019 25/1427**

Model Compression with Adversarial Robustness: A Unified Optimization Framework
⏬MetaQuant: Learning to Quantize by Learning to Penetrate Non-differentiable Quantization
**Positive-Unlabeled** Compression on the Cloud
A Mean Field Theory of Quantized Deep Networks: The Quantization-Depth Trade-Off
⏬Focused Quantization for Sparse CNNs
✅Normalization Helps Training of **Quantized LSTM** 
✅**Post training 4-bit quantization** of convolutional networks for rapid-deployment

Generalization Error Analysis of Quantized Compressive Learning. Random Projections with **Asymmetric Quantization**

Dichotomize and Generalize: PAC-Bayesian **Binary Activated** Deep Neural Networks
Communication-Efficient **Distributed Learning** via Lazily Aggregated Quantized Gradients
PowerSGD: Practical **Low-Rank Gradient Compression** for Distributed Optimization. Double Quantization for **Communication-Efficient Distributed** Optimization. Qsparse-local-SGD: **Distributed SGD** with Quantization, Sparsification and Local Computations.

On the Downstream Performance of **Compressed Word Embeddings**
Deep Generative **Video Compression**

### **NeurIPS 2018 18/1010**

A Linear Speedup Analysis of Distributed Deep Learning with **Sparse and Quantized Communication**
GradiVeQ: **Vector Quantization** for Bandwidth-Efficient Gradient Aggregation in **Distributed CNN Training**
Communication Compression for **Decentralized Training**

Neural Proximal Gradient Descent for **Compressive Imaging**
Joint Autoregressive and Hierarchical Priors for Learned **Image Compression**
BinGAN: Learning Compact Binary Descriptors with a Regularized **GAN**

### **NeurIPS 2017 14/679**

⏬Soft-to-Hard **Vector Quantization** for End-to-End Learning Compressible Representations
⏬**Training Quantized Nets: A Deeper Understanding**
Compression-aware **Training** of Deep Networks

QSGD: Communication-Efficient **SGD** via Gradient Quantization and Encoding
Towards Accurate **Binary** Convolutional Neural Network

Learning to Inpaint for **Image Compression**

### **NeurIPS 2016 10/569**

Mistake Bounds for **Binary Matrix Completion**

------

### **CVPR 2022 61/2072**

⏬MiniViT: Compressing **Vision Transformers** with Weight Multiplexing
⏬**Learnable Lookup Table** for Neural Network Quantization
⏬AdaSTE: An **Adaptive Straight-Through Estimator** to Train Binary Neural Networks
⏬Training Quantised Neural Networks with **STE** Variants: the Additive Noise Annealing Algorithm
⏬Channel Balancing for Accurate Quantization of **Winograd Convolutions**
⏬Implicit Feature Decoupling with **Depthwise Quantization**
⏬**Data-Free** Network Compression via Parametric Non-uniform Mixed Precision Quantization
⏬Mr.BiQ: **Post-Training** Non-Uniform Quantization based on Minimizing the Reconstruction Error
✅Nonuniform-to-Uniform Quantization: Towards Accurate Quantization via **Generalized Straight-Through Estimation**

AlignQ: Alignment Quantization with **ADMM**-based Correlation Preservation
**Mutual Quantization** for Cross-Modal Search with **Noisy Labels**
It's All In the Teacher: **Zero-Shot Quantization** Brought Closer to the Teacher
IntraQ: Learning Synthetic Images with Intra-Class Heterogeneity for **Zero-Shot Network Quantization**
Global Context with Discrete Diffusion in **Vector Quantised** Modelling for Image Generation. Autoregressive **Image Generation** using **Residual Quantization**

**Compressing Models with Few Samples**: Mimicking then Replacing
Instance-Aware Dynamic Neural Network Quantization

PILC: Practical Image Lossless Compression with an End-to-end **GPU Oriented Neural Framework**

PokeBNN: A **Binary** Pursuit of Lightweight Accuracy
Unsupervised Representation Learning for **Binary** Networks by Joint Classifier Learning

LSVC: A Learning-based Stereo **Video Compression** Framework
Learning based Multi-modality Image and **Video Compression**
Accelerating Video Object Segmentation with Compressed **Video** Density-preserving Deep **Point Cloud Compression**
OCSampler: Compressing **Videos** to One Clip with Single-step Sampling
RIDDLE: **Lidar Data Compression** with Range Image Deep Delta Encoding
SASIC: Stereo **Image Compression** with Latent Shifts and Stereo Attention
ELIC: Efficient Learned **Image Compression** with Unevenly Grouped Space-Channel Contextual Adaptive Coding
Joint Global and Local Hierarchical Priors for Learned **Image Compression**
LC-FDNet: Learned Lossless **Image Compression** with Frequency Decomposition Network
Neural Data-Dependent Transform for Learned **Image Compression**
The Devil Is in the Details: Window-based Attention for **Image Compression**
HerosNet: Hyperspectral Explicable Reconstruction and Optimal Sampling Deep Network for **Snapshot Compressive Imaging**
Unified Multivariate Gaussian Mixture for Efficient Neural **Image Compression**
Quantization-aware Deep Optics for Diffractive **Snapshot** Hyperspectral **Imaging**

### **CVPR 2021 41/1660**

⏬AQD: Towards Accurate Quantized Object Detection
⏬Automated **Log-Scale Quantization** for Low-Cost Deep Neural Networks
⏬**Distribution-Aware** Adaptive Multi-Bit Quantization
⏬Towards Efficient **Tensor Decomposition**-Based DNN Model Compression With Optimization Framework
⏬QPP: **Real-Time Quantization Parameter** Prediction for Deep Neural Networks
Permute, Quantize, and Fine-Tune: Efficient Compression of Neural Networks
✅Diversifying Sample Generation for Accurate **Data-Free Quantization** 
✅Network Quantization With Element-Wise Gradient Scaling. 
✅Learnable Companding Quantization for Accurate **Low-Bit** Neural Networks

Improving Accuracy of **Binary** Neural Networks Using Unbalanced Activation Distribution. Zero-Shot Adversarial Quantization. Bi-GCN: **Binary** Graph Convolutional Network
**Binary** Graph Neural Networks. **Binary** TTC: A Temporal Geofence for Autonomous Navigation

Content-Aware **GAN Compression**
Memory-Efficient Network for Large-Scale **Video** Compressive Sensing
FVC: A New Framework Towards Deep **Video Compression** in Feature Space. Deep Homography for Efficient Stereo **Image Compression**
Checkerboard Context Model for Efficient Learned **Image Compression**
What's in the Image? Explorable Decoding of **Compressed Images**
**Slimmable** Compressive Autoencoders for Practical Neural **Image Compression**
VoxelContext-Net: An Octree Based Framework for **Point Cloud Compression**

### **CVPR 2020 35/1465**

⏬**Low-Rank** Compression of Neural Nets: Learning the Rank of Each Layer
⏬AdaBits: Neural Network Quantization With **Adaptive Bit-Widths**
⏬Adaptive **Loss-Aware Quantization** for Multi-Bit Networks
⏬The Knowledge Within: Methods for **Data-Free Model Compression**
⏬Towards Efficient Model Compression via Learned **Global Ranking**
⏬Structured Compression by **Weight Encryption** for Unstructured Pruning and Quantization Deep Implicit Volume Compression
Learning Better Lossless Compression Using Lossy Compression
APQ: Joint Search for Network Architecture, Pruning and Quantization Policy
✅ZeroQ: A Novel Zero Shot Quantization Framework 
✅Training Quantized Neural Networks With a Full-Precision Auxiliary Module

✅Forward and Backward Information Retention for Accurate **Binary** Neural Networks
Automatic Neural Network Compression by **Sparsity-Quantization** Joint Learning: A Constrained Optimization-Based Approach
Attention Convolutional **Binary** Neural Tree for Fine-Grained Visual Categorization
BSP-Net: Generating Compact Meshes via **Binary** Space Partitioning

Structured **Multi-Hashing** for Model Compression
**GAN Compression**: Efficient Architectures for Interactive Conditional GANs
OctSqueeze: Octree-Structured Entropy Model for **LiDAR Compression**
M-LVC: Multiple Frames Prediction for Learned **Video Compression**
Scale-Space Flow for End-to-End Optimized **Video Compression**
Learning for **Video Compression** With Hierarchical Quality and Recurrent Enhancement
DAVD-Net: Deep Audio-Aided **Video** Decompression of Talking Heads
Plug-and-Play Algorithms for Large-Scale **Snapshot Compressive Imaging**
Learned **Image Compression** With Discretized Gaussian Mixture Likelihoods and Attention Modules
A **Spatial RNN** Codec for End-to-End **Image Compression**

### **CVPR 2019 37/1294**

⏬Efficient Neural Network Compression
⏬Compressing Convolutional Neural Networks via **Factorized Convolutional Filters**
SeerNet: Predicting Convolutional Neural Network Feature-Map **Sparsity** Through **Low-Bit** Quantization
⏬Exploiting **Kernel Sparsity** and Entropy for Interpretable CNN Compression
⏬Cross Domain Model Compression by Structurally **Weight Sharing**
✅Accelerating Convolutional Neural Networks via **Activation Map Compression
**✅Fully Quantized Network for Object Detection 
✅Learning to Quantize Deep Networks by Optimizing Quantization Intervals With **Task Loss** 
✅Quantization Networks
✅HAQ: Hardware-Aware Automated Quantization With Mixed Precision

Compressing Unknown Images With **Product Quantizer** for Efficient Zero-Shot Classification
Cascaded Projection: End-To-End Network Compression and Acceleration

Structured **Binary** Neural Networks for Accurate Image Classification and Semantic Segmentation
Learning Channel-Wise Interactions for **Binary** Convolutional Neural Networks
Circulant **Binary** Convolutional Networks: Enhancing the Performance of 1-Bit DCNNs With Circulant Back Propagation
**Binary Ensemble** Neural Network: More Bits per Network or More Networks per Bit?
A Main/Subsidiary Network Framework for Simplifying **Binary** Neural Networks. Simultaneously Optimizing Weight and Quantizer of **Ternary** Neural Network Using Truncated Gaussian Approximation

Practical Full Resolution Learned Lossless **Image Compression**
Learning Image and **Video Compression** Through Spatial-Temporal Energy Compaction
DVC: An End-To-End Deep **Video Compression** Framework
Deep **Spherical Quantization** for **Image Search**
Feature Distillation: DNN-Oriented **JPEG Compression** Against Adversarial Examples

### **CVPR 2018 23/979**

Two-Step Quantization for Low-Bit Neural Networks
⏬Explicit **Loss-Error-Aware Quantization** for **Low-Bit** Deep Neural Networks
⏬**Net2Vec**: Quantifying and Explaining How Concepts Are Encoded by Filters in Deep Neural Networks
**Feature Quantization** for Defending Against Distortion of Images
**Quantization of Fully Convolutional Networks** for Accurate **Biomedical Image Segmentation**
✅SYQ: **Learning Symmetric Quantization** for Efficient Deep Neural Networks
✅**Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference**

A Biresolution Spectral Framework for **Product Quantization**
CLIP-Q: Deep Network Compression Learning by **In-Parallel Pruning-Quantization**
Wide Compression: Tensor Ring Nets

Learning Convolutional Networks for Content-Weighted **Image Compression**
Deformation Aware **Image Compression**
Improved Lossy **Image Compression** With Priming and Spatially Adaptive Bit Rates for **Recurrent Networks**
Conditional Probability Models for Deep **Image Compression**
Compressed **Video** Action Recognition
Multi-Frame Quality Enhancement for Compressed **Video**
Learning Compressible 360° **Video** Isomers

### **CVPR 2017 21/783**

⏬**Weighted-Entropy-Based Quantization** for Deep Neural Networks
⏬On Compressing Deep Models by **Low Rank and Sparse Decomposition**
⏬Deep Quantization: **Encoding Convolutional Activations** with Deep Generative Model
✅Deep Learning with **Low Precision** by Half-Wave Gaussian Quantization

Local **Binary Convolutional** Neural Networks
BRISKS: **Binary** Features for Spherical Images on a Geodesic Grid

Full Resolution **Image Compression** with **Recurrent Neural Networks**
Model-Based Iterative Restoration for Binary **Document Image Compression** with Dictionary Learning

### **CVPR 2016 12/643**

**Quantized Convolutional Neural Networks for Mobile Devices**
Fast Training of Triplet-Based Deep **Binary Embedding Networks**

------

### **ECCV 2022**

⏬Non-uniform Step Size Quantization for Accurate **Post-Training Quantization**
FOSTER: Feature Boosting and Compression for **Class-Incremental Learning**
⏬Fine-Grained Data Distribution Alignment for **Post-Training Quantization** ⏬Explicit Model Size Control and Relaxation via Smooth Regularization for **Mixed-Precision** Quantization
⏬**Mixed-Precision** Neural Network Quantization via Learned Layer-Wise Importance
⏬BASQ: Branch-Wise Activation-Clipping Search Quantization for **Sub-4-Bit** Neural Networks
⏬Patch Similarity Aware Data-Free Quantization for **Vision Transformers** ⏬Connecting Compression **Spaces** with **Transformer** for Approximate **Nearest Neighbor Search**
⏬Towards Accurate Network Quantization with Equivalent Smooth Regularizer
⏬Symmetry Regularization and Saturating Nonlinearity for Robust Quantization
QISTA-ImageNet: A Deep Compressive **Image Sensing** Framework Solving ℓq\ell_q-Norm Optimization Problem
⏬Synergistic Self-Supervised and Quantization Learning
Bitwidth-Adaptive Quantization-Aware Neural Network **Training**: A **Meta-Learning** Approach
⏬RDO-Q: Extremely Fine-Grained Channel-Wise Quantization via Rate-Distortion Optimization
✅PTQ4ViT: Post-Training Quantization for **Vision Transformers** with Twin Uniform Quantization

✅AdaBin: Improving **Binary** Neural Networks with Adaptive Binary Sets Recurrent Bilinear Optimization for **Binary** Neural Networks Towards Accurate **Binary** Neural Networks via Modeling Contextual Dependencies Lipschitz Continuity Retained **Binary** Neural Network

CADyQ: Content-Aware Dynamic Quantization for **Image Super-Resolution** **High-Resolution Image Generation**from Vector-Quantized Codes Learning Spatiotemporal Frequency-Transformer for Compressed **Video Super-Resolution**
A Codec Information Assisted Framework for Efficient Compressed **Video Super-Resolution** AlphaVC: High-Performance and Efficient Learned **Video Compression** Neural **Video Compression** Using GANs for Detail Synthesis and Propagation Ensemble Learning Priors Driven Deep Unfolding for Scalable **Video** Snapshot Compressive Imaging CANF-VC: Conditional Augmented **Normalizing Flows** for **Video Compression** **Vector Quantized** **Image-to-Image Translation** Unleashing Transformers: Parallel Token Prediction with Discrete Absorbing Diffusion for Fast

Content Adaptive Latents and Decoder for Neural **Image Compression**
Optimizing **Image Compression** via Joint Learning with Denoising
Contextformer: A Transformer with Spatio-Channel Attention for Context Modeling in Learned **Image Compression**
Content-Oriented Learned **Image Compression**
Expanded Adaptive Scaling Normalization for End to End **Image Compression**
Implicit Neural Representations for **Image Compression**
Dual-Domain Self-Supervised Learning and Model Adaption for **Deep Compressive Imaging**

**Quantized GAN** for Complex Music Generation from Dance Videos
A Cloud 3D Dataset and Application-Specific Learned Image Compression in **Cloud 3D**
**Point Cloud Compression** with Sibling Context and Surface Priors
**Point Cloud Compression** with Range Image-Based Entropy Model for Autonomous Driving
Privacy-Preserving **Action Recognition** via Motion Difference Quantization
PoseGPT: Quantization-Based **3D Human Motion** Generation and Forecasting
VQFR: Blind **Face Restoration** with **Vector-Quantized Dictionary** and Parallel Decoder
Fast-Vid2Vid: **Spatial-Temporal Compression** for **Video-to-Video Synthesis**
Auto-Regressive **Image Synthesis** with Integrated Quantization

### **ECCV 2020**

⏬Stable **Low-rank Tensor Decomposition** for Compression of Convolutional Neural Network
⏬DBQ: A Differentiable Branch Quantizer for Lightweight Deep Neural Networks
⏬Differentiable Joint Pruning and Quantization for Hardware Efficiency
⏬Generative Low-bitwidth Data Free Quantization
Finding Non-Uniform Quantization Schemes using Multi-Task Gaussian Processes
Search What You Want: Barrier Panelty **NAS** for **Mixed Precision** Quantization
⏬HMQ: Hardware Friendly **Mixed Precision** Quantization Block for CNNs
FTL: A universal framework for training **low-bit DNNs** via Feature Transfer
✅Post-Training Piecewise Linear Quantization for Deep Neural Networks

Learning Architectures for **Binary** Networks
☑️ReActNet: Towards Precise **Binary** Neural Network with Generalized Activation Functions
BATS: **Binary** ArchitecTure Search

Deep Spatial-angular Regularization for Compressive Light Field Reconstruction over Coded Apertures
End-to-End Low Cost Compressive Spectral Imaging with Spatial-Spectral Self-Attention
Deep Transferring Quantization
QuEST: Quantized Embedding Space for Transferring Knowledge

GAN Slimming: All-in-One **GAN Compression** by A Unified Optimization Framework
Quantization Guided **JPEG** Artifact Correction
PAMS: Quantized **Super-Resolution** via Parameterized Max Scale
Early Exit Or Not: Resource-Efficient Blind Quality Enhancement for **Compressed Images **
Deep **Image Compression** using Decoder Side Information
Task-Aware Quantization Network for **JPEG Image Compression**
Learning Memory Augmented Cascading Network for **Compressed Sensing of Images **

Conditional Entropy Coding for Efficient **Video Compression **
Content Adaptive and Error Propagation Aware Deep **Video Compression**
Improving Deep **Video Compression** by Resolution-adaptive Flow Coding
High-quality Single-model Deep **Video Compression** with Frame-Conv3D and Multi-frame Differential Modulation
BIRNAT: **Bidirectional Recurrent Neural** Networks with Adversarial Training for **Video Snapshot Compressive Imaging**
Sequential Convolution and Runge-Kutta Residual Architecture for **Image Compressed** Sensing
Self-supervised Bayesian Deep Learning for **Image Recovery** with Applications to Compressive Sensing

### **ECCV 2018**

**Clustering Convolutional Kernels** to Compress Deep Neural Networks
AMC: **AutoML** for Model Compression and Acceleration on Mobile Devices
**Product Quantization** Network for Fast **Image Retrieval**
⏬Extreme Network Compression via Filter Group Approximation
⏬LSQ++: Lower running time and higher recall in multi-codebook quantization
Quantized Densely Connected U-Nets for Efficient Landmark Localization
⏬Learning Compression from Limited **Unlabeled** Data
✅Quantization Mimic: Towards Very Tiny CNN for Object Detection

LQ-Nets: Learned Quantization for Highly Accurate and Compact Deep Neural Networks
Coreset-Based Neural Network Compression
Constraint-Aware Deep Neural Network Compression

LAPRAN: A Scalable Laplacian Pyramid Reconstructive Adversarial Network for Flexible
Compressing the Input for CNNs with the First-Order Scattering Transform

Highly-Economized Multi-View **Binary** Compression for Scalable Image Clustering
Hashing with **Binary** Matrix Pursuit
TBN: Convolutional Neural Network with **Ternary** Inputs and **Binary** Weights
Training **Binary** Weight Networks via Semi-Binary Decomposition

Joint optimization for **compressive video sensing** and reconstruction under hardware constraints
**Video Compression** through Image Interpolation
Deep Kalman Filtering Network for **Video Compression** Artifact Reduction
**Compressive Sensing Reconstruction** **Value-aware Quantization** for Training and Inference of Neural Networks

### **ECCV 2016**

------

### **ICML 2022 32/1234**

Self-supervised learning with random-projection quantizer for **speech recognition.**
Diffusion bridges **vector quantized** variational **autoencoders**.
⏬**Overcoming Oscillations in Quantization-Aware Training**
⏬Optimal Clipping and Magnitude-aware Differentiation for Improved **Quantization-aware Training**.
DAdaQuant: Doubly-adaptive quantization for **communication-efficient Federated Learning **
⏬SDQ: Stochastic Differentiable Quantization with **Mixed Precision**
⏬Secure Quantized Training for Deep Learning

Correlated Quantization for **Distributed Mean Estimation and Optimization
SQ-VAE: **Variational** Bayes on Discrete Representation with Self-annealed Stochastic Quantization. Fast Lossless Neural Compression with **Integer-Only** Discrete Flows. Easy Variational Inference for Categorical Models via an Independent **Binary** Approximation. Accurate Quantization of Measures via Interacting Particle-based Optimization. Bitwidth Heterogeneous **Federated Learnin**g with Progressive Weight Dequantization.

### **ICML 2021 38/1183**

ActNN: Reducing Training Memory Footprint via **2-Bit Activation** Compressed **Training**.
⏬Double-Win Quant: Aggressively Winning Robustness of Quantized Deep Neural Networks via Random Precision **Training and Inference.**
⏬Differentiable Dynamic Quantization with **Mixed Precision** and Adaptive Resolution.
✅I-BERT: Integer-only BERT Quantization 
✅HAWQ-V3: Dyadic Neural Network Quantization. 
✅Accurate Post Training Quantization With **Small Calibration Sets**.

Training Quantized Neural Networks to Global Optimality via Semidefinite Programming.
On Perceptual Lossy Compression: The Cost of Perceptual Reconstruction and An Optimal **Training** Framework.
Distributed Second Order Methods with Fast Rates and **Compressed Communication.**
Soft then Hard: Rethinking the Quantization in Neural **Image Compression**.

### **ICML 2020 29/1085**

Supervised Quantile Normalization for **Low Rank Matrix Factorization**.
⏬Divide and Conquer: Leveraging Intermediate Feature Representations for **Quantized Training** of Neural Networks
Auto**GAN-Distiller**: Searching to Compress Generative Adversarial Networks.
Accelerating Large-Scale Inference with Anisotropic **Vector Quantization**.
**Differentiable Product Quantization** for End-to-End Embedding Compression.
**Multi-Precision** Policy Enforced Training (MuPPET) : A Precision-Switching Strategy for Quantised Fixed-Point Training of CNNs.
✅Towards Accurate **Post-training** Network Quantization via Bit-Split and Stitching.
✅Up or Down? Adaptive Rounding for **Post-Training Quantization**

Train Big, Then Compress: **Rethinking Model Size for Efficient Training and Inference of Transformers**

Training **Binary** Neural Networks using the Bayesian Learning Rule
Training **Binary** Neural Networks through Learning with Noisy Supervision
Deep Molecular Programming: A Natural Implementation of **Binary**-Weight ReLU Neural Networks.

A Quantile-based Approach for Hyperparameter Transfer Learning.
Quantized Decentralized Stochastic Learning over Directed Graphs.
Moniqua: Modulo Quantized Communication in **Decentralized SGD**
Variational Bayesian Quantization
Feature Quantization Improves **GAN Training**

### **ICML 2019 23/774**

⏬Compressed Factorization: Fast and Accurate **Low-Rank Factorization** of Compressively-Sensed Data.
Faster Algorithms for **Binary Matrix Factorization**
Lossless or Quantized Boosting with **Integer Arithmetic.
**✅Improving Neural Network Quantization without Retraining using Outlier Channel Splitting.
✅Same, Same But Different: Recovering Neural Network Quantization Error Through Weight Factorization.

POPQORN: Quantifying Robustness of **Recurrent Neural Networks**.

### **ICML 2018 17/621**

Towards Binary-Valued Gates for Robust **LSTM Training**
⏬Weightless: **Lossy weight encoding** for deep neural network compression.
**Error Compensated Quantized SGD** and its Applications to Large-scale Distributed Optimization.
Deep k-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for **Compressing Deep Convolutions**

### **ICML 2017 8/434**

Toward Efficient and Accurate Covariance **Matrix Estimation on Compressed Data**
ProtoNN: Compressed and Accurate **kNN** for Resource-scarce Devices.
Real-Time Adaptive **Image Compression**

------

### **AAAI 2022 22/1624**

Anisotropic Additive Quantization for Fast Inner Product Search.
⏬**Convolutional Neural Network Compression** through Generalized **Kronecker Product Decomposition**
Equal Bits: Enforcing Equally Distributed **Binary** Network Weights.
Improved Gradient-Based Adversarial Attacks for Quantized Networks.
⏬Deeply **Tensor Compressed Transformers** for End-to-End Object Detection
BATUDE: Budget-Aware Neural Network Compression Based on **Tucker Decomposition** From Dense to Sparse: Contrastive Pruning for Better Pre-trained **Language Model Compression.**

AsyncFL: Asynchronous **Federated Learning** Using Majority Voting with Quantized Model Updates (Student Abstract).
Two-Stage Octave Residual Network for End-to-End **Image Compression**
Towards End-to-End **Image Compression** and Analysis with Transformers.
OoDHDR-Codec: Out-of-Distribution Generalization for **HDR Image Compression**.
OctAttention: Octree-Based Large-Scale Contexts Model for **Point Cloud Compression**.
Contrastive Quantization with Code Memory for **Unsupervised Image Retrieval**

### **AAAI 2021 35/1961**

⏬A **Compression-Compilation** Co-Design Framework Towards Real-Time Object Detection on Mobile Devices.
⏬**Post-training Quantization** with Multiple Points: Mixed Precision without Mixed Precision.
⏬OPQ: Compressing Deep Neural Networks with **One-shot Pruning-Quantization.
**✅**YOLObile**: Real-Time Object Detection on Mobile Devices via Compression-Compilation Co-Design.

DPFPS: Dynamic and Progressive Filter Pruning for Compressing Convolutional Neural Networks from Scratch.
✅Distribution Adaptive INT8 Quantization for Training CNNs.
Scalable Verification of Quantized Neural Networks.
Robust Model Compression Using Deep Hypotheses.
Provable Benefits of Overparameterization in Model Compression: From Double Descent to Pruning Neural Networks.

Training **Binary** Neural Network without Batch Normalization for **Image Super-Resolution.**
SA-BNN: State-Aware **Binary** Neural Network.
Compressing Deep Convolutional Neural Networks by Stacking Low-dimensional **Binary** Convolution Filters. Memory and Computation-Efficient Kernel SVM via **Binary** Embedding and Ternary Model Coefficients. TRQ: **Ternary** Neural Networks With Residual Quantization.

Optimizing Information Theory Based Bitwise Bottlenecks for Efficient **Mixed-Precision** Activation Quantization.
**Stochastic Precision Ensemble**: Self-Knowledge Distillation for Quantized Deep Neural Networks. FracBits: **Mixed Precision** Quantization via Fractional Bit-Widths.
**Vector Quantized** Bayesian Neural Network Inference for Data Streams.
**Binary Matrix Factorisation** via Column Generation.
Accelerating Neural Machine Translation with **Partial Word Embedding Compression. **
Weakly Supervised Deep Hyperspherical Quantization for **Image Retrieval**.

### **AAAI 2020 36/1864**

✅**Q-BERT**: Hessian Based Ultra Low Precision Quantization of BERT.
HLHLp: Quantized Neural Networks Training for Reaching Flat Minima in Loss Surface.
Towards Accurate Low **Bit-Width Quantization** with Multiple Phase Adaptations. Embedding Compression with Isotropic Iterative Quantization.
Norm-Explicit Quantization: Improving **Vector Quantization** for Maximum Inner Product Search.
Aggregated Learning: A **Vector-Quantization** Approach to Learning Neural Network Classifiers. **Vector Quantization**-Based Regularization for **Autoencoders**
**Few Shot Network Compression via Cross Distillation.**
**Compressed Self-Attention for Deep Metric Learning**.
AutoCompress: An Automatic DNN Structured **Pruning** Framework for Ultra-High Compression Rates.
Layerwise **Sparse** Coding for Pruned Deep Neural Networks with Extreme Compression Ratio.

**Quantized Compressive Sampling of Stochastic Gradients** for Efficient Communication in **Distributed Deep Learning**.
Indirect Stochastic Gradient Quantization and Its Application in **Distributed Deep Learning**.
On the Discrepancy between the Theoretical Analysis and Practical Implementations of Compressed Communication for **Distributed Deep Learning**

Adversarial Attack on Deep Product Quantization Network for **Image Retrieval**
Learned **Video Compression** via Joint Spatial-Temporal Correlation Exploration.
Efficient Querying from **Weighted Binary Codes**

### **AAAI 2019 21/1343**

Online Embedding Compression for Text Classification Using **Low Rank Matrix Factorization**
Deep Neural Network Quantization via Layer-Wise Optimization Using **Limited Training Data.**

**Compressing Recurrent Neural Networks** with Tensor Ring for Action Recognition.
**Multi-Precision** Quantized Neural Networks via Encoding Decomposition of {-1, +1}
Universal Approximation Property and Equivalence of Stochastic Computing-Based Neural Networks and **Binary**Neural Networks.
Efficient Quantization for Neural Networks with **Binary** Weights and Low Bitwidth Activations.
An Efficient **Compressive Convolutional** Network for Unified Object Detection and Image Compression.

Similarity Preserving Deep Asymmetric Quantization for **Image Retrieval.**

### **AAAI 2018 18/1102**

⏬Adaptive Quantization for Deep Neural Network

From Hashing to CNNs: Training **Binary** Weight Networks via Hashing.
Distributed Composite Quantization.
SqueezedText: A Real-Time Scene Text Recognition by **Binary Convolutional** Encoder-Decoder Network
Tensorized Projection for High-Dimensional **Binary Embedding**.
On the Optimal Bit Complexity of Circulant **Binary Embedding.**
AdaComp : Adaptive Residual Gradient Compression for Data-Parallel **Distributed Training.** Deep Neural Network Compression With **Single and Multiple Level Quantization**

Product Quantized Translation for **Fast Nearest Neighbor Search**

### **AAAI 2017 16/786**

How to Train a Compact **Binary** Neural Network with High Accuracy?

**Compressed K-Means** for Large-Scale Clustering
Ordinal Constrained Binary Code Learning for **Nearest Neighbor Search.**

### **AAAI 2016 8/691**

Affinity Preserving Quantization for Hashing: A **Vector Quantization** Approach to Compact Learn Binary Codes.

------

### **IJCAI 2022 16/863**

⏬MultiQuant: Training Once for **Multi-bit Quantization** of Neural Networks
Exploring **Binary** Classification Hidden within **Partial Label Learning**
✅FQ-ViT: Post-Training Quantization for Fully Quantized Vision Transformer.
✅RAPQ: Rescuing Accuracy for Power-of-Two Low-bit Post-training Quantization
✅BiFSMN: **Binary** Neural Network for Keyword Spotting

D-DPCC: Deep Dynamic **Point Cloud Compression** via 3D Motion Prediction
Semantic **Compression Embedding** for Generative Zero-Shot Learning

### **IJCAI 2021 14/721**

⏬A **Compression-Compilation** Framework for **On-mobile Real-time BERT** Applications
Automatic **Mixed-Precision** Quantization Search of **BERT**
⏬Decomposable-Net: Scalable **Low-Rank Compression** for Neural Networks

Uncertainty-aware **Binary** Neural Networks
Hardware-friendly Deep Learning by Network Quantization and **Binarization**

AutoReCon: **Neural Architecture Search**-based Reconstruction for **Data-free Compression**

### **IJCAI 2020 20/778**

Compressed Self-Attention for Deep Metric Learning with **Low-Rank Approximation**
⏬Direct Quantization for **Training** Highly Accurate **Low Bit-width** Deep Neural Networks
AdaBERT: Task-Adaptive **BERT Compression** with **Differentiable Neural Architecture Search.**

✅**Overflow Aware Quantization**: Accelerating Neural Network Inference by **Low-bit Multiply-Accumulate Operations**

Channel-Level Variable Quantization Network for Deep **Image Compression**

### **IJCAI 2019 20/965**

⏬**Learning Low-precision Neural Networks without Straight-Through Estimator (STE)**
⏬KCNN: **Kernel-wise Quantization** to Remarkably Decrease Multiplications in Convolutional Neural Network
⏬**Low-Bit Quantization** for Attributed Network Representation Learning.

Beyond **Product Quantization**: Deep Progressive Quantization for **Image Retrieval.**

Reading selectively via **Binary Input Gated Recurrent Unit**
Rectified **Binary** Convolutional Networks for Enhancing the Performance of **1-bit DCNNs**.
Deep Recurrent Quantization for Generating Sequential **Binary** Codes. **Binarized** Neural Networks for Resource-Efficient Hashing with Minimizing Quantization Loss

### **IJCAI 2018 14/870**

Dynamically Hierarchy Revolution: DirNet for Compressing **Recurrent Neural Network on Mobile Devices**.

Complementary **Binary** Quantization for Joint Multiple Indexing
Deterministic **Binary Filters** for Convolutional Neural Networks
Towards Enabling **Binary Decomposition** for Partial Label Learning.

### **IJCAI 2017 8/781**

**Rescale-Invariant SVM** for Binary Classification
**Binary Linear Compression** for Multi-label Classification

### **IJCAI 2016 8/658**

Towards **Convolutional Neural Networks Compression** via **Global Error Reconstruction**

------

### **ICLR 2022 31/1094**

⏬**Information Bottleneck: Exact Analysis of (Quantized) Neural Networks
**Toward Efficient **Low-Precision Training:** Data Format Optimization and Hysteresis Quantization 
EXACT: Scalable **Graph Neural NetworksTraining** via **Extreme Activation Compression**
✅F8Net: **Fixed-Point 8-bit** Only Multiplication for Network Quantization
✅**QDrop**: Randomly Dropping Quantization for Extremely Low-bit **Post-Training Quantization**
✅SQuant: On-the-Fly Data-Free Quantization via **Diagonal Hessian Approximation**
✅8-bit Optimizers via Block-wise Quantization

**Encoding Weights of Irregular Sparsity** for Fixed-to-Fixed Model Compression
✅Unified Visual **Transformer Compression**
**Vector-quantized** Image Modeling with Improved **VQGAN**
DKM: **Differentiable k-Means Clustering** Layer for Neural Network Compression

**Language model compression with weighted low-rank factorization**
**Exploring extreme parameter compression for pre-trained language models**

Entroformer: A Transformer-based Entropy Model for Learned **Image Compression**

### **ICLR 2021 24/860**

Sparse Quantized Spectral Clustering
⏬Simple Augmentation Goes a Long Way: ADRL for DNN Quantization
Neural gradients are near-lognormal: improved quantized and sparse **training**
Incremental few-shot learning via **vector quantization** in deep embedded space
✅BRECQ: Pushing the Limit of **Post-Training Quantization** by Block Reconstruction
✅BSQ: Exploring Bit-Level Sparsity for **Mixed-Precision** Neural Network Quantization
✅**Training** with Quantization Noise for Extreme Model Compression

Lossless Compression of Structured Convolutional Models via Lifting
**Drop-Bottleneck**: Learning Discrete Compressed Representation for Noise-Robust Exploration. Overfitting for Fun and Profit: **Instance-Adaptive Data Compression**

Reducing the Computational Cost of Deep Generative Models with **Binary** Neural Networks
High-Capacity Expert **Binary** Networks
Multi-Prize Lottery Ticket Hypothesis: Finding Accurate **Binary** Neural Networks by Pruning A Randomly Weighted Network. BiPointNet: **Binary** Neural Network for **Point Clouds**
Faster **Binary Embedding**s for Preserving Euclidean Distances

Degree-Quant: Quantization-Aware **Training** for **Graph Neural Networks**
✅UMEC: Unified model and embedding compression for efficient **recommendation** systems
Self-Supervised Learning of **Compressed Video** Representations
Hierarchical Autoregressive Modeling for Neural **Video Compression**
Learning Accurate Entropy Model with Global Reference for Image Compression

### **ICLR 2020 25/687**

⏬Linear Symmetric Quantization of Neural Networks for **Low-precision** Integer Hardware
⏬**And the Bit Goes Down: Revisiting the Quantization of Neural Networks**
⏬AutoQ: Automated **Kernel-Wise** Neural Network Quantization
⏬Gradient ℓ1\ell_1 Regularization for Quantization Robustness
Scalable Model Compression by Entropy Penalized Reparameterization
BlockSwap: **Fisher-guided Block Substitution** for Network Compression on a Budget
⏬FSNet: Compression of Deep Convolutional Neural Networks by Filter Summary
Probabilistic Connection Importance Inference and Lossless Compression of Deep Neural Networks
✅Additive Powers-of-Two Quantization: An Efficient Non-uniform Discretization for Neural Networks 
✅Learned Step Size quantization

Learning representations for **binary**-classification **without backpropagation**
BinaryDuo: Reducing Gradient Mismatch in **Binary Activation** Network by Coupling Binary Activations
Training **binary** neural networks with real-to-binary convolutions
Critical initialisation in continuous approximations of **binary** neural networks

Neural Epitome Search for Architecture-Agnostic Network Compression
**Compressive Transformers** for Long-Range Sequence Modelling
**Decentralized Deep Learning** with Arbitrary Communication Compression
Sampling-Free Learning of **Bayesian Quantized** Neural Networks
HiLLoC: lossless **image compression** with hierarchical latent variable models

### **ICLR 2019 23/502**

⏬**Understanding Straight-Through Estimator** in Training Activation Quantized Neural Nets. 
Double Viterbi: **Weight Encoding for High Compression Ratio** and Fast On-Chip Reconstruction for Deep Neural Network
⏬ProxQuant: Quantized Neural Networks via Proximal Operators
**Analysis of Quantized Model**s
**Defensive Quantization: When Efficiency Meets Robustness**
Minimal Random Code Learning: Getting Bits Back from Compressed Model Parameters. ⏬On the Universal Approximability and Complexity Bounds of **Quantized ReLU Neural Networks**
Integer Networks for Data Compression with Latent-Variable Models
⏬Per-Tensor Fixed-Point Quantization of the Back-Propagation Algorithm. Practical lossless compression with latent variables using bits back coding.
✅Relaxed Quantization for Discretized Neural Networks

ARM: Augment-REINFORCE-Merge Gradient for Stochastic **Binary** Networks
Learning Recurrent **Binary**/Ternary Weights
An Empirical study of **Binary** Neural Networks' Optimisation.

From Hard to Soft: Understanding Deep Network Nonlinearities via **Vector Quantization** and Statistical Inference. Learnable **Embedding Space** for Efficient Neural Architecture Compression

Context-adaptive Entropy Model for End-to-end Optimized **Image Compression**

### **ICLR 2018 16/336**

**Variational** Network Quantization. 
⏬**Loss-aware Weight Quantization** of Deep Networks
⏬Adaptive Quantization of Neural Networks ☑️Model compression via distillation and quantization
✅Alternating **Multi-bit Quantization** for **Recurrent Neural Networks**

The High-Dimensional Geometry of **Binary** Neural Networks
Espresso: Efficient Forward Propagation for **Binary** Deep Neural Networks.

Deep Gradient Compression: Reducing the Communication Bandwidth for **Distributed Training**
Viterbi-based Pruning for **Sparse Matrix** with Fixed and High Index Compression Ratio. A Compressed Sensing View of Unsupervised Text Embeddings, Bag-of-n-Grams, and LSTMs. Compressing Word Embeddings via Deep Compositional Code Learning

Variational **image compression** with a scale hyperprior

### **ICLR 2017 10/198**

Towards the Limit of Network Quantization
**Soft Weight-Sharing** for Neural Network Compression
Training Compressed **Fully-Connected Networks** with a Density-Diversity Penalty
**Sigma Delta Quantized Networks**
✅Incremental Network Quantization: Towards Lossless CNNs with **Low-precision** Weights

Optimal **Binary Autoencoding** with Pairwise Correlations
Trained **Ternary** Quantization.

Lossy **Image Compression** with Compressive Autoencoders

### **ICLR 2016 4/80**

✅**Deep Compression**: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding
Data Representation and Compression Using Linear-Programming Approximations
Compression of Deep Convolutional Neural Networks for **Fast and Low Power Mobile Applications**

Variable Rate I**mage Compression** with **Recurrent Neural Networks**