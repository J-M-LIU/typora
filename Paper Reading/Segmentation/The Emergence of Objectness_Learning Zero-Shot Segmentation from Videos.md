# The Emergence of Objectness: Learning Zero-Shot Segmentation from Videos



## Introdutcion

本文探讨了如何通过观察未标记视频来同时建模物体的运动和分割。研究假设视频包含同一场景的不同视角，通过移动组件进行关联。研究提出的模型通过两个独立的路径分解视频帧：一个是外观路径，为单张图像输出基于特征的区域分割；另一个是运动路径，为一对图像输出运动特征。然后，模型将这两个路径结合在一起，形成联合区域流特征表示，并预测段流（segment flow），为整个场景提供移动区域的大致特征。通过训练模型最小化基于段流的视图合成错误，外观和运动路径自动学习区域分割和流估计，而无需从低级边缘或光流开始构建。

![image-20231217222702673](https://cdn.jsdelivr.net/gh/J-M-LIU/pic-bed@master//img/image-20231217222702673.png)



## Segmentation by Appearance-Motion Decomposition

模型能够分割出移动对象，而不必知道它们是什么和有多少。该模型在未标记的通用视频集合上进行训练，可以直接部署在新图像(视频)上，以产生(运动)目标分割。在训练或测试期间不需要人工注释。

![image-20231217233445372](https://cdn.jsdelivr.net/gh/J-M-LIU/pic-bed@master//img/image-20231217233445372.png)

模型由两个部分组成：一个单帧静态图像分割网络和一个双帧运动网络。图像分割网络是完全卷积的神经网络，负责对单一图像进行分割，生成软掩码；运动网络基于像素的运动特征来预测两帧之间的运动。

具体来说，模型工作流程如下：

1. **外观路径（Appearance Pathway）**：输入单个RGB图像，输出特征基础的分割掩码。每个掩码都表示图像中的一个区域，并且所有掩码的和等于1，这意味着每个像素都被分配到一个区域。
2. **运动路径（Motion Pathway）**：使用PWC-Net架构，但不使用预训练的权重，以提取两帧图像之间的运动对应特征。这些特征将用于构建每个掩码的平均运动特征。
3. **段流表示（Segment Flow Representation）**：通过结合外观和运动路径，创建一个联合的段流表示，用于视角合成。基本上，这是通过计算每个掩码区域的平均运动特征并预测整个区域的单个2D流向量来完成的。
4. **重建目标**：通过segment flow和mask重建目标帧，以最小化重建误差。通过这种方式，模型可以根据它们的段流合成帧。

