# Hybrid Spatial-Temporal Entropy Modelling for Neural Video Compression



## Introduction

已有的编码工作多直接使用神经图像编码器中熵编码的方案（自回归先验、层次先验等），如之前的DCVC-TCM，RD(率失真)性能有限，仅略优于2013年发布的H.265。在视频熵模型的设计中，时空相关性尚未得到充分挖掘。因此，本文提出了新的并行友好的熵模型设计方案，引入对偶空间先验和自适应量化，有效地利用空间相关性和时间相关性。

因此，提出了一种综合熵模型，可以有效地利用空间相关性和时间相关性，从而帮助神经视频编解码器超越最新的传统标准H.266。特别地，引入了潜先验和对偶空间先验。潜在先验探索了跨帧潜在表示的时间相关性。使用前一帧的量化潜表示来预测其在当前帧中的分布。

**Contribution**

- **对偶空间先验**：auto-regressive先验是一种序列化的解决方案，遵循严格的扫描顺序。这种解决方案对并行不友好，推理速度很慢。本文提出的dual spatial prior 是一个两步编码解决方案，遵循棋盘上下文模型。在这种方法中，所有通道首先按照相同的编码顺序进行编码（即先编码偶数位置，然后用作奇数位置的上下文），这样可以更有效地处理各种视频内容。
- **自适应量化机制**：传统的编码器通过调整量化参数来实现平滑的速率调整。但是，大多数神经编码器缺乏这种调整能力，并使用固定的量化步骤。
  - 首先由用户设置全局量化步长（QS）；
  - 与通道级别QS相乘，不同的通道可能包含有关视频内容的不同信息，因此，根据通道的重要性进行适当的调整是有意义的。这与通道注意力机制类似，其中不同的通道根据其重要性被分配不同的权重。
  - 由熵模型生成的空间-通道级量化QS与之前的结果相乘。这可以看作是一个更为细致的量化调整，它考虑了视频内容在空间上的细节和变化。

## Methodology





![image-20231011180712121](https://cdn.jsdelivr.net/gh/J-M-LIU/pic-bed@master//img/image-20231011180712121.png)







![image-20231011200732034](https://cdn.jsdelivr.net/gh/J-M-LIU/pic-bed@master//img/image-20231011200732034.png)
