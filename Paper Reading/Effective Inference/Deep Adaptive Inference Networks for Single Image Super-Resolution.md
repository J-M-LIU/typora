# Deep Adaptive Inference Networks for Single Image Super-Resolution



## Introduction

现有的SISR网络通常有固定的深度和结构，这可能导致资源浪费，因为不是所有图像部分都需要同样的计算处理。一个SISR模型的训练一旦完成，无论场景如何，推断过程是确定性的且只依赖于模型的结构和输入图像的大小。因此，图像内容feature和资源自适应是更具有启发性的，

![image-20231014205636153](https://cdn.jsdelivr.net/gh/J-M-LIU/pic-bed@master//img/image-20231014205636153.png)

图1(c)显示了使用EDSR [17]与不同数量的残差块的SISR结果。可以看到，使用8个残差块就足以将一个纹理较少的平滑补丁进行超分辨率处理。相反，对于一个细节丰富的补丁，至少需要24个残差块。因此，平等对待整张图像并处理所有区域将导致计算资源的浪费。因此，本文提出一个深度自适应的推断网络，在精度和效率/复杂度之间实现更好的权衡。

之前的方法在patch-level上进行自适应推理，且只针对于feature，本文的AdaDSR满足pixel-level自适应，且进一步满足硬件资源约束。



## Methodology



### 具有空间变异网络深度的AdaDSR

<img src="https://cdn.jsdelivr.net/gh/J-M-LIU/pic-bed@master//img/image-20231014205532736.png" alt="image-20231014205532736" style="zoom:40%;" />

单图像超分辨率旨在学习从其低分辨率 (LR) 观察$x$重构高分辨率图像$j$的映射, 并可以写为:
$$
\hat{y}=F(x;\Theta)\quad
$$
其中, $F$ 表示具有网络参数 $\Theta$ 的SISR网络。一个代表性类别的深度SISR网络, 由三个主要模块组成: 特征提取$F_e$, 残差块和高分辨率重建$F_r$​。几个代表性的SISR模型,例如, SRResNet[15], EDSR[17]和RCAN[41], 都属于这一类别。以EDSR为例，令$Z_0=F_e(x)$。然后可以将残差块的输出表示为：
$$
z'=z_0+\sum_{l=1}^DF_l(z_{l-1};\Theta_l)\quad
$$
$l-th$残差块的输出可写为 $z_l = z_{l-1} + F_l(z_{l-1},\Theta_l)$；重建过程可写作 $\hat{y} = F_r(z^{'};\Theta_r)$

如图1所示, 超分辨率的难度是空间变化的。例如, 不需要遍历方程(2)中的所有 $D$ 残差块来重构光滑的区域。对于具有丰富和详细纹理的区域, 通常需要更多的残差块来达到高质量的重建。因此, 引入一个与 $z_0$ 具有相同空间大小的**2D网络深度图** $d(0\leq d_{ij}\leq D)$。直观地说, 对于光滑区域, 网络深度$d_{ij}$ 更小, 对于细节丰富的区域, 它更大。为了便于空间自适应推理, 修改方程(2)为:
$$
z^{\prime}=z_0+\sum_{l=1}^DG_l(d)\odot F_l(z_{l-1};\Theta_l)
$$
其中$\odot$表示元素逐项乘积。此处, $G_l(d_{ij})$ 定义为:
$$
\left.\mathcal{G}_l(d_{ij})=\left\{\begin{array}{cc}0,&d_{ij}<l-1\\1,&d_{ij}>l\\d_{ij}-(l-1),&otherwise\end{array}\right.\right..
$$
公式$G_l(d_{ij})$的定义是关于如何在空间自适应网络深度中选择是否使用特定的残差块。具体来说, 该函数基于以下规则:

1. 如果$d_{ij}$(某一位置的网络深度)小于$l-1$, 那么函数的值为0。这意味着在该特定位置,不使用编号为$l$ 的残差块。

2. 如果$d_{ij}$ 大于$l$, 则函数的值为1。这表示在该位置, 使用编号为$l$ 的残差块。

3. 其他情况下, 函数的值为$l-(l-1)$, 简化后就是1。 

这三种情况共同定义了网络如何在不同的空间位置选择使用或不使用特定的残差块。有助于实现空间自适应的推断, 即在纹理丰富的区域使用更多的残差块, 而在平滑的区域使用较少的残差块。



### Lightweight Adapter Module 轻量级适配器模块

在这一部分，论文介绍了一个轻量级的适配器模块P，该模块的目的是预测2D的网络深度图 $d$。为了适应局部图像内容，这个模块会为图像的平滑区域生成较低的网络深度，为细节区域生成较高的网络深度。

如图2，适配器模块P将特征图 $z_0$ 作为输入，由四个带有PReLU的卷积层组成，后面跟着一个带有ReLU的卷积层。使用公式(4)为每个残差块生成掩码 $\mathbf{m}_l$。需要注意的是，$\mathbf{m}_l$可能不是二进制掩码，但包含许多零。因此可以构建一个稀疏的残差块，它可以省略计算对于零掩码值的区域，从而实现有效的自适应推理。为了满足效率约束，我们还将所需的网络深度d作为输入到适配器中：
$$
\mathbf{d}=\mathcal{P}(\mathbf{z}_0,d;\Theta_a),
$$


### Learning Object

**重建损失($L_{rec}$):**
$L_{rec}=||y-\hat{y}||_1$ 其中, $y$ 是高分辨率的真实图像, 而 $\hat{y}$ 是通过AdaDSR得到的超分辨率图像。这个损失确保了模型产生的超分辨率图像与真实的高分辨率图像尽可能接近。
**网络深度损失($L_{depth}$):**
$$
L_{depth}=max(0,\bar{d}-d)
$$
其中，$\overline{d}$是模型预测的网络深度图的平均值, 而$d$ 是期望的网络深度。这个损失确保模型的有效性, 鼓励模型有一个接近所需深度的网络深度。最后, 整体的学习目标 $L$ 结合了这两个损失, 并由一个超参数 $\lambda$ 来平衡它们，在实验中 $\lambda$ 设置为0.01.
$$
L=L_{rec}+\lambda L_{depth}
$$
