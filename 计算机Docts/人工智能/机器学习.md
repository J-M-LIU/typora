## 机器学习

### Classification 分类

- 泛化错误：描述学生机器在从样品数据中学习之后，离教师机器之间的差距的函数
- 经验错误：模型在数据集训练上的误差

事先已经知道有多少类，给每组样本一个具体的类别，有训练数据

#### Linear and Nonlinear 

- 线性分类：拟合率低，速度快（如一个分类函数族 ***y=w·x+b***，可以计算每个样本点到线性分类函数的平面距离之和，和最小的函数即是拟合度最好的分类函数
- 非线性分类器：拟合度高

### Regression 回归

- 线性
- 非线性

### 强化学习

- 算法与外部环境交互，每个动作得到一个反馈，通过反馈来学习

- 强化学习不会添加标签，而是通过环境激励反馈

### 监督学习

#### 步骤

1. 找一个函数族
2. 找一个优化准则
3. 找到最优函数

### 非监督学习

#### 聚类

聚类结果的分组标准，即具体的物理含义需要自分析处理

大部分聚类算法不知道聚类的数量等达到多少 是最优的

即聚类算法是无训练数据的



### How does Machine Learning work



#### Logistic regression 逻辑回归

linear regression是用来做回归（预测）的，logistic regression是用来做分类的

如果用 ![[公式]](https://www.zhihu.com/equation?tex=x) 表示训练数据， ![[公式]](https://www.zhihu.com/equation?tex=%5Ctheta) 表示模型参数， ![[公式]](https://www.zhihu.com/equation?tex=h) 表示预测的输出， ![[公式]](https://www.zhihu.com/equation?tex=y) 表示训练数据的标签

2分类问题实际上是一个伯努利分布：

![[公式]](https://www.zhihu.com/equation?tex=P%28y%3D1%7Cx%3B%5Ctheta%29%3Dh_%7B%5Ctheta%7D%28x%29+)

![[公式]](https://www.zhihu.com/equation?tex=P%28y%3D0%7Cx%3B%5Ctheta%29%3D1-h_%7B%5Ctheta%7D%28x%29)

可以将上面2个式子合并成一个表达式：

![[公式]](https://www.zhihu.com/equation?tex=P%28y%7Cx%3B%5Ctheta%29%3D%28h_%7B%5Ctheta%7D%28x%29%29%5E%7By%7D%281-h_%7B%5Ctheta%7D%28x%29%29%5E%7B1-y%7D)

logistic regression的目标函数是根据**最大似然**思想求得的。



**通过sigmoid变换，映射成[0,1]的概率分布，即可实现<u>*二分类问题*</u>。**

**通常被用来计算一个例子属于一个特殊分类的概率（比如说这份邮件是垃圾邮件的概率)**

如果概率大于50%，算作1， 属于这个分类，如果概率小于50%，算作0 ，不属于这个分类，这使得他成为了一个binary classifier.

他和线性回归的联系在于计算， 他也会计算输入的features(+bias term) 的加了权重的和，但是它并不像线性回归那样直接给出结果，他给出这个结果的logistic.

![img](https://pic2.zhimg.com/50/v2-836d75dc9ac25bd0e4706069f7fa0dd7_hd.jpg?source=1940ef5c)![img](https://pic2.zhimg.com/80/v2-836d75dc9ac25bd0e4706069f7fa0dd7_1440w.jpg?source=1940ef5c)

logistic(logit)-- 被叫做sigmoid function（s-形状)，输出的数在0-1之间。

只要logistic regression model测出来了一个例子属于一个特殊分类的概率，他就可以很容易预测出来是否属于这个分类。

比如说概率小于0.5，y = 0不属于； 概率大于0.5，y=1,属于。

<u>***回归和分类是一体的，可以用回归模型解决分类问题。***</u>



#### KNN k近邻 

在一个样本点处设置一个范围，在此样本点范围阈值内的其他数据点分类，出现分类频率最高的，则该样本点属于此类

k的选择和距离的选择都会影响到算法的效果













